{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import glob\n",
    "import os\n",
    "import geopandas as gpd\n",
    "\n",
    "pd.set_option(\"display.max_columns\", None)\n",
    "# pd.set_option('display.max_rows', None)\n",
    "# pd.set_option('display.max_columns', None)\n",
    "# pd.set_option('display.width', None)\n",
    "# pd.set_option('display.max_colwidth', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# WWF ECOREGION AND USA COUNTY MAP DATA\n",
    "\n",
    "# read in ecoregion map data and US county data\n",
    "\n",
    "county_path = input(\"Enter the file path: \")\n",
    "counties = gpd.read_file(county_path)\n",
    "\n",
    "map_path = input(\"Enter the file path: \")\n",
    "ecomap = gpd.read_file(map_path)\n",
    "\n",
    "# ecotest = ecomap.loc[ecomap['unique_id'] == 420].reset_index(drop=True)\n",
    "# county_inner = counties.loc[0]\n",
    "# county_outer = counties.loc[1]\n",
    "# county_split = counties.loc[(counties['NAME'] == 'Brown') & (counties['STATE_NAME'] == 'Ohio')]\n",
    "\n",
    "\n",
    "eco_county = []\n",
    "# eco_id = {'unique_id': str(ecotest['unique_id'].values[0])}\n",
    "# eco_county.append(eco_id)\n",
    "# selected_counties = []\n",
    "\n",
    "# check whether a each county is inside or intersects an ecoregion or if ecoregion is inside a county\n",
    "for i in range(len(ecomap)):\n",
    "    # get unique id of each ecoregion\n",
    "    eco_id = {\"unique_id\": str(ecomap.loc[i, \"unique_id\"])}\n",
    "\n",
    "    selected_counties = []\n",
    "\n",
    "    for j in range(len(counties)):\n",
    "        # check whether county is within ecoregion\n",
    "        # contains = ecomap.loc[i, 'geometry'].contains(counties.loc[j, 'geometry'])\n",
    "        # intersects = ecomap.loc[i, 'geometry'].intersects(counties.loc[j, 'geometry'])\n",
    "        within = ecomap.loc[i, \"geometry\"].within(counties.loc[j, \"geometry\"])\n",
    "\n",
    "        # print(counties.loc[i, 'NAME'])\n",
    "        # if county is in ecoregion push to selected counties list\n",
    "        # if contains == True:\n",
    "        if within == True:\n",
    "            # if contains == True or intersects == True:\n",
    "            selected_counties.append(\n",
    "                {\n",
    "                    \"county\": counties.loc[j, \"NAME\"],\n",
    "                    \"state\": counties.loc[j, \"STATE_NAME\"],\n",
    "                }\n",
    "            )\n",
    "            # eco_id['eco_counties'] = selected_counties\n",
    "    # add selected counties to eco_id dict\n",
    "    eco_id[\"eco_counties\"] = selected_counties\n",
    "    # push counties to eco_county list\n",
    "    eco_county.append(eco_id)\n",
    "\n",
    "\n",
    "full_county = []\n",
    "\n",
    "# check if there are any counties in ecoregion for usa. if they are push to full county list\n",
    "for i in range(len(eco_county)):\n",
    "    if eco_county[i][\"eco_counties\"]:\n",
    "        full_county.append(eco_county[i])\n",
    "\n",
    "na_county = []\n",
    "\n",
    "# check if ecoregion has unique_id. if it does push to na_county\n",
    "for i in range(len(full_county)):\n",
    "    if full_county[i][\"unique_id\"] != \"nan\":\n",
    "        na_county.append(full_county[i])\n",
    "\n",
    "county_data = pd.DataFrame(na_county)\n",
    "eco_county_data = pd.json_normalize(\n",
    "    na_county, record_path=\"eco_counties\", meta=[\"unique_id\"]\n",
    ")\n",
    "\n",
    "# Extract relevant columns\n",
    "county_data = eco_county_data[[\"unique_id\", \"county\"]]\n",
    "state_data = eco_county_data[[\"unique_id\", \"state\"]]\n",
    "\n",
    "# Group by unique_id\n",
    "county_group = county_data.groupby(\"unique_id\")[\"county\"].apply(list).reset_index()\n",
    "state_group = state_data.groupby(\"unique_id\")[\"state\"].apply(list).reset_index()\n",
    "\n",
    "# Merge grouped data\n",
    "final_eco_county = pd.merge(county_group, state_group, on=\"unique_id\", how=\"left\")\n",
    "\n",
    "# Convert to JSON\n",
    "eco_county_json = final_eco_county.to_json(orient=\"records\", force_ascii=False)\n",
    "\n",
    "\n",
    "file = open(\"eco_county_prep.json\", \"w\")\n",
    "file.write(eco_county_json)\n",
    "file.close"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# USA ECO COUNTIES\n",
    "eco_county_path = input(\"Enter the file path: \")\n",
    "eco_county = pd.read_json(eco_county_path)\n",
    "\n",
    "# convert to dataframe and group county and state into dict.\n",
    "county = [\"county\", \"state\"]\n",
    "eco_county[\"eco_counties\"] = eco_county[county].to_dict(orient=\"records\")\n",
    "\n",
    "# group by unique id\n",
    "eco_group = eco_county.groupby(\"unique_id\")[\"eco_counties\"].apply(list).reset_index()\n",
    "# eco_group = eco_county.groupby('unique_id')['eco_counties']\n",
    "\n",
    "# convert to list\n",
    "eco_counties = eco_group[\"eco_counties\"].to_list()\n",
    "\n",
    "eco_counties_test = eco_counties\n",
    "\n",
    "# remove duplicates from list of counties and states\n",
    "for j in range(len(eco_counties_test)):\n",
    "    eco_counties_test[j] = [\n",
    "        i\n",
    "        for n, i in enumerate(eco_counties_test[j])\n",
    "        if i not in eco_counties_test[j][n + 1 :]\n",
    "    ]\n",
    "\n",
    "\n",
    "eco_counties_df = pd.Series(eco_counties_test, name=\"counties_final\")\n",
    "\n",
    "group_final = eco_group.merge(\n",
    "    eco_counties_df, left_index=True, right_index=True\n",
    ").reindex(columns=[\"unique_id\", \"counties_final\"])\n",
    "\n",
    "group_final_json = group_final.to_json(orient=\"records\", force_ascii=False)\n",
    "repr(group_final_json)\n",
    "\n",
    "file = open(\"eco_county_within.json\", \"w\")\n",
    "file.write(group_final_json)\n",
    "file.close"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# USA ECO COUNTIES\n",
    "\n",
    "\n",
    "# USA ECO COUNTIES\n",
    "\n",
    "ods_path = input(\"Enter the file path: \")\n",
    "eco_ods = pd.read_excel(ods_path, index_col=0, sheet_name=None, engine=(\"odf\"))\n",
    "\n",
    "# put all sheets in one dataframe\n",
    "eco_df = pd.concat([v for k, v in eco_ods.items()])\n",
    "eco_df.reset_index(inplace=True)\n",
    "\n",
    "# add unique id column with ecoregion value\n",
    "eco_df[\"unique_id\"] = \"397\"\n",
    "\n",
    "\n",
    "# USA ECO COUNTIES\n",
    "# remove duplicate species\n",
    "eco_df.drop_duplicates([\"Scientific Name\"], inplace=True, ignore_index=True)\n",
    "\n",
    "\n",
    "# USA ECO COUNTIES\n",
    "\n",
    "eco_subset = eco_df[\n",
    "    [\n",
    "        \"Plant Type\",\n",
    "        \"Scientific Name\",\n",
    "        \"Common Name\",\n",
    "        \"Plant Family\",\n",
    "        \"Native Status\",\n",
    "        \"unique_id\",\n",
    "    ]\n",
    "]\n",
    "\n",
    "eco_json = eco_subset.to_json(orient=\"records\", force_ascii=False)\n",
    "repr(eco_json)\n",
    "\n",
    "file = open(\"eco_county_397.json\", \"w\")\n",
    "file.write(eco_json)\n",
    "file.close"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# USA ECO COUNTIES\n",
    "\n",
    "# read in all json files and merge into one dataframe\n",
    "json_dir = input(\"Enter the file path: \")\n",
    "\n",
    "json_pattern = os.path.join(json_dir, \"*.json\")\n",
    "file_list = glob.glob(json_pattern)\n",
    "\n",
    "dfs = []\n",
    "for file in file_list:\n",
    "    with open(file) as f:\n",
    "        json_data = pd.json_normalize(json.loads(f.read()))\n",
    "        json_data[\"site\"] = file.rsplit(\"/\", 1)[-1]\n",
    "    dfs.append(json_data)\n",
    "counties_init = pd.concat(dfs)\n",
    "counties_init.reset_index(drop=True, inplace=True)\n",
    "counties_init.drop(\"site\", 1, inplace=True)\n",
    "\n",
    "\n",
    "counties_init[\"Plant Type\"].replace(\n",
    "    to_replace=\"Tree, Shrub\", value=\"Tree\", inplace=True\n",
    ")\n",
    "counties_init[\"Plant Type\"].replace(\n",
    "    to_replace=\"Herb (annual)\", value=\"Wildflower\", inplace=True\n",
    ")\n",
    "counties_init[\"Plant Type\"].replace(\n",
    "    to_replace=\"Herb (perennial)\", value=\"Wildflower\", inplace=True\n",
    ")\n",
    "counties_init[\"Plant Type\"].replace(\n",
    "    to_replace=\"Shrub, Herb (perennial)\", value=\"Wildflower\", inplace=True\n",
    ")\n",
    "counties_init[\"Plant Type\"].replace(\n",
    "    to_replace=\"Graminoid (perennial)\", value=\"Graminoid\", inplace=True\n",
    ")\n",
    "counties_init[\"Plant Type\"].replace(\n",
    "    to_replace=\"Graminoid (annual)\", value=\"Graminoid\", inplace=True\n",
    ")\n",
    "counties_init[\"Plant Type\"].replace(\n",
    "    to_replace=\"Herb (annual or perennial)\", value=\"Wildflower\", inplace=True\n",
    ")\n",
    "counties_init[\"Plant Type\"].replace(\n",
    "    to_replace=\"Herb (biennial or perennial)\", value=\"Wildflower\", inplace=True\n",
    ")\n",
    "counties_init[\"Plant Type\"].replace(\n",
    "    to_replace=\"Herb (biennial)\", value=\"Wildflower\", inplace=True\n",
    ")\n",
    "counties_init[\"Plant Type\"].replace(\n",
    "    to_replace=\"Herb (annual or biennial)\", value=\"Wildflower\", inplace=True\n",
    ")\n",
    "counties_init[\"Plant Type\"].replace(\n",
    "    to_replace=\"Shrub, Herb (annual or perennial)\", value=\"Wildflower\", inplace=True\n",
    ")\n",
    "counties_init[\"Plant Type\"].replace(\n",
    "    to_replace=\"Graminoid (annual or perennial)\", value=\"Graminoid\", inplace=True\n",
    ")\n",
    "counties_init[\"Plant Type\"].replace(\n",
    "    to_replace=\"Shrub, Herb (biennial or perennial)\", value=\"Wildflower\", inplace=True\n",
    ")\n",
    "counties_init[\"Plant Type\"].replace(\n",
    "    to_replace=\"Shrub, Herb (annual)\", value=\"Wildflower\", inplace=True\n",
    ")\n",
    "counties_init[\"Plant Type\"].replace(\n",
    "    to_replace=\"Shrub (annual or perennial)\", value=\"Shrub\", inplace=True\n",
    ")\n",
    "counties_init[\"Plant Type\"].replace(to_replace=\"Herb\", value=\"Wildflower\", inplace=True)\n",
    "counties_init[\"Plant Type\"].replace(\n",
    "    to_replace=\"Vine, Herb (annual or perennial)\", value=\"Vine\", inplace=True\n",
    ")\n",
    "counties_init[\"Plant Type\"].replace(\n",
    "    to_replace=\"Vine, Herb (perennial)\", value=\"Vine\", inplace=True\n",
    ")\n",
    "counties_init[\"Plant Type\"].replace(\n",
    "    to_replace=\"Shrub, Graminoid (perennial)\", value=\"Graminoid\", inplace=True\n",
    ")\n",
    "counties_init[\"Plant Type\"].replace(\n",
    "    to_replace=\"Shrub, Herb (annual or perennial)\", value=\"Wildflower\", inplace=True\n",
    ")\n",
    "counties_init[\"Plant Type\"].replace(\n",
    "    to_replace=\"Vine, Herb (annual)\", value=\"Vine\", inplace=True\n",
    ")\n",
    "counties_init[\"Plant Type\"].replace(\n",
    "    to_replace=\"Vine, Shrub\", value=\"Vine\", inplace=True\n",
    ")\n",
    "counties_init[\"Plant Type\"].replace(\n",
    "    to_replace=\"Vine, Shrub, Herb (perennial)\", value=\"Vine\", inplace=True\n",
    ")\n",
    "counties_init[\"Plant Type\"].replace(\n",
    "    to_replace=\"Shrub, Herb (biennial or perennial)\", value=\"Wildflower\", inplace=True\n",
    ")\n",
    "counties_init[\"Plant Type\"].replace(\n",
    "    to_replace=\"Tree, Vine, Shrub\", value=\"Shrub\", inplace=True\n",
    ")\n",
    "counties_init[\"Plant Type\"].replace(\n",
    "    to_replace=\"Tree, Shrub, Herb (perennial)\", value=\"Wildflower\", inplace=True\n",
    ")\n",
    "counties_init[\"Plant Type\"].replace(\n",
    "    to_replace=\"Vine, Shrub, Graminoid (perennial)\", value=\"Graminoid\", inplace=True\n",
    ")\n",
    "\n",
    "counties_init.loc[77973, \"Plant Type\"] = \"Tree\"\n",
    "counties_init.loc[93777, \"Plant Type\"] = \"Tree\"\n",
    "\n",
    "\n",
    "counties_unique = counties_init.drop_duplicates([\"Scientific Name\"])\n",
    "counties_unique.drop(\"unique_id\", 1, inplace=True)\n",
    "counties_group = (\n",
    "    counties_init.groupby(\"Scientific Name\")[\"unique_id\"].apply(list).reset_index()\n",
    ")\n",
    "\n",
    "counties_final = pd.merge(\n",
    "    counties_unique, counties_group, on=\"Scientific Name\", how=\"left\"\n",
    ")\n",
    "common_miss = counties_final.loc[pd.isna(counties_final[\"Common Name\"]), :]\n",
    "\n",
    "\n",
    "final_json = counties_final.to_json(orient=\"records\", force_ascii=False)\n",
    "repr(final_json)\n",
    "\n",
    "final_miss = common_miss.to_json(orient=\"records\", force_ascii=False)\n",
    "repr(final_miss)\n",
    "\n",
    "file = open(\"eco_county_prep.json\", \"w\")\n",
    "file.write(final_json)\n",
    "file.close"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# USA ECO COUNTIES\n",
    "county_path = input(\"Enter the file path: \")\n",
    "eco_county = pd.read_json(county_path)\n",
    "\n",
    "# convert to dataframe and group county and state into dict.\n",
    "county = [\"county\", \"state\"]\n",
    "eco_county[\"eco_counties\"] = eco_county[county].to_dict(orient=\"records\")\n",
    "\n",
    "# group by unique id\n",
    "eco_group = eco_county.groupby(\"unique_id\")[\"eco_counties\"].apply(list).reset_index()\n",
    "# eco_group = eco_county.groupby('unique_id')['eco_counties']\n",
    "\n",
    "# convert to list\n",
    "eco_counties = eco_group[\"eco_counties\"].to_list()\n",
    "\n",
    "eco_counties_test = eco_counties\n",
    "\n",
    "# remove duplicates from list of counties and states\n",
    "for j in range(len(eco_counties_test)):\n",
    "    eco_counties_test[j] = [\n",
    "        i\n",
    "        for n, i in enumerate(eco_counties_test[j])\n",
    "        if i not in eco_counties_test[j][n + 1 :]\n",
    "    ]\n",
    "\n",
    "\n",
    "eco_counties_df = pd.Series(eco_counties_test, name=\"counties_final\")\n",
    "\n",
    "group_final = eco_group.merge(\n",
    "    eco_counties_df, left_index=True, right_index=True\n",
    ").reindex(columns=[\"unique_id\", \"counties_final\"])\n",
    "\n",
    "group_final_json = group_final.to_json(orient=\"records\", force_ascii=False)\n",
    "repr(group_final_json)\n",
    "\n",
    "file = open(\"eco_county_within.json\", \"w\")\n",
    "file.write(group_final_json)\n",
    "file.close"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "eco",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
