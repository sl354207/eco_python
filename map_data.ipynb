{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import json\n",
    "\n",
    "pd.set_option('display.max_columns', None)\n",
    "# pd.set_option('display.max_rows', None)\n",
    "# pd.set_option('display.max_columns', None)\n",
    "# pd.set_option('display.width', None)\n",
    "# pd.set_option('display.max_colwidth', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " \n",
    "# WWF ECOREGION MAP DATA\n",
    "\n",
    "\n",
    "# read in wwf map data\n",
    "map = pd.read_json(\n",
    "    '/home/muskrat/Documents/eco_data/wwf_map_data/wwf_terr_ecos.json')\n",
    "# ej = pd.read_json(\n",
    "#     '/media/muskrat/060A9B8E0A9B78FF/map_final/eco_map.geojson')\n",
    "# print(ej['features'][0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    " \n",
    "# WWF ECOREGION MAP DATA\n",
    "\n",
    "# unpack json file and convert to dataframe\n",
    "\n",
    "\n",
    "def unpack(df, column, fillna=None):\n",
    "    ret = None\n",
    "    if fillna is None:\n",
    "        tmp = pd.DataFrame((d for idx, d in df[column].iteritems()))\n",
    "        ret = pd.concat([df.drop(column, axis=1), tmp], axis=1)\n",
    "    else:\n",
    "        tmp = pd.DataFrame((d for idx, d in\n",
    "                            df[column].iteritems())).fillna(fillna)\n",
    "        ret = pd.concat([df.drop(column, axis=1), tmp], axis=1)\n",
    "    return ret\n",
    "\n",
    "\n",
    "unpacked_features = unpack(map, 'features', 0)\n",
    "\n",
    "unpacked_properties = unpack( unpacked_features, 'properties', 0)\n",
    "\n",
    "# unpacked_properties.drop_duplicates(subset=['unique_id'], keep='first', inplace=True)\n",
    "# unpacked_properties.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# ej3 = unpack(unpacked_properties, 'geometry', 0)\n",
    "\n",
    "# ej3.dropna(subset=['unique_id'], inplace=True)\n",
    "# ej3.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# # df = pd.DataFrame(ej3.coordinates[0])\n",
    "\n",
    "# # df1 = df[0][0]\n",
    "\n",
    "# selected = []\n",
    "\n",
    "# for i in range(len(unpacked_properties)):\n",
    "#     # df2 = pd.DataFrame(ej3.coordinates[i])\n",
    "#     # df3 = df2[0][0]\n",
    "#     df3 = unpacked_properties.geometry[i]['coordinates'][-1][-1]\n",
    "#     if len(df3) > 2:\n",
    "#         selected.append(df3[-1])\n",
    "#     else:\n",
    "#         selected.append(df3)\n",
    "# # merged_data = ej3['coordinates'][0][0][0]\n",
    "\n",
    "# import math\n",
    "\n",
    "# desk = []\n",
    "\n",
    "# for i in range(len(selected)):\n",
    "#     d = selected[i]\n",
    "\n",
    "#     deesk = []\n",
    "#     for j in range(len(d)):\n",
    "#         factor = 10.0 ** 3\n",
    "#         t = math.trunc(d[j] * factor) / factor\n",
    "#         deesk.append(t)\n",
    "#     desk.append(deesk)\n",
    "\n",
    "# unpacked_properties['point'] = desk\n",
    "# unpacked_properties.rename(columns={'point': 'coordinates'}, inplace=True)\n",
    "\n",
    "# ecoregions = unpacked_properties[['unique_id', 'name', 'TYPE', 'coordinates']]\n",
    "\n",
    "# ej3.iloc[[0], []] = merged_data\n",
    "\n",
    "\n",
    "# create subset of dataframe just to check data\n",
    "# ej3 = unpacked_properties[['OBJECTID', 'ECO_NAME', 'ECO_NUM', 'ECO_ID', 'eco_code']]\n",
    "\n",
    "# rename eco_code column\n",
    "unpacked_properties.rename(columns={'eco_code': 'ECOREGION_CODE'}, inplace=True)\n",
    "unpacked_properties.drop(unpacked_properties.columns[0], axis=1, inplace=True)\n",
    "unpacked_properties.drop(unpacked_properties.columns[0], axis=1, inplace=True)\n",
    "\n",
    "# unpacked_properties.insert(0, 'type', 'Feature')\n",
    "\n",
    "# create subset of dataframe\n",
    "ecoregions_subset = unpacked_properties[['unique_id', 'ECOREGION_CODE']]\n",
    "\n",
    "merged_data = pd.merge(unpacked_properties, ecoregions_subset, on='ECOREGION_CODE', how='left')\n",
    "\n",
    "\n",
    "data_dict = merged_data.to_dict(orient='records')\n",
    "\n",
    "# data_dict = unpacked_properties.to_dict(orient='records')\n",
    "# add properties wrapper key to values\n",
    "\n",
    "properties_key = \"properties\"\n",
    "\n",
    "properties_dictionary = [{properties_key: property} for property in data_dict]\n",
    "\n",
    "# convert to json\n",
    "json_data = json.dumps(properties_dictionary)\n",
    "\n",
    "properties_df = pd.DataFrame(properties_dictionary)\n",
    "\n",
    "unpacked_features.drop(unpacked_features.columns[0], axis=1, inplace=True)\n",
    "unpacked_features.drop(unpacked_features.columns[1], axis=1, inplace=True)\n",
    "\n",
    "unpacked_features.insert(0, 'type', 'Feature')\n",
    "# unpacked_features.insert(0, 'type', 'Feature')\n",
    "\n",
    "# join dataframes\n",
    "\n",
    "map_data = pd.concat([unpacked_features, properties_df], axis=1, join='inner')\n",
    "map_json = map_data.to_json(orient='records', force_ascii=False)\n",
    "# eco = ecoregions.to_json(orient='records', force_ascii=False)\n",
    "\n",
    "# map_json = properties_df.to_json(orient='records', force_ascii=False)\n",
    "repr(map_json)\n",
    "\n",
    "# add start and end tag to json\n",
    "\n",
    "map_final = '{\"type\":\"FeatureCollection\", \"features\": ' + map_json + '}'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    " \n",
    "# WWF ECOREGION MAP DATA\n",
    "\n",
    "# write to json file\n",
    "file = open(\"dataset.json\", \"w\")\n",
    "file.write(map_final)\n",
    "file.close\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    " \n",
    "ecomap = gpd.read_file(\n",
    "    '/media/muskrat/060A9B8E0A9B78FF/maptest/terr_map.geojson')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    " \n",
    "marinemap = gpd.read_file(\n",
    "    '/media/muskrat/060A9B8E0A9B78FF/maptest/marine_map.geojson')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    " \n",
    "ecomap['name'] = ecomap['ECO_NAME']\n",
    "\n",
    "ecomap[\"unique_id\"] = ecomap[\"unique_id\"].astype(\"float32\")\n",
    "\n",
    "ecomap['unique_id'] = pd.to_numeric(ecomap['unique_id'], downcast='integer')\n",
    "\n",
    "ecomap[\"unique_id\"] = ecomap[\"unique_id\"].convert_dtypes()\n",
    "\n",
    "ecomap['unique_id'] = ecomap['unique_id'].astype(str)\n",
    "\n",
    "ecomap.drop_duplicates(subset=['unique_id'], keep='first', inplace=True)\n",
    "\n",
    "marinemap['name'] = ''\n",
    "\n",
    "marinemap.loc[marinemap['TYPE'] == 'PPOW', 'name'] = marinemap['PROVINC']\n",
    "\n",
    "marinemap.loc[marinemap['TYPE'] == 'MEOW', 'name'] = marinemap['ECOREGION']\n",
    "\n",
    "marinemap = marinemap[['unique_id', 'name', 'TYPE', 'geometry']]\n",
    "\n",
    "ecomap['TYPE'] = 'TEOW'\n",
    "\n",
    "ecomap = ecomap[['unique_id', 'name', 'TYPE', 'geometry']]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    " \n",
    "\n",
    "marinemap.to_file(\"marine_map.geojson\", driver='GeoJSON')\n",
    "\n",
    "ecomap.to_file(\"terr_map.geojson\", driver='GeoJSON')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ecomap = gpd.read_file(\n",
    "    '/media/muskrat/060A9B8E0A9B78FF/eco_data/wwf_terr_map_data/terr_map.geojson')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    " \n",
    "marinemap = gpd.read_file(\n",
    "    '/media/muskrat/060A9B8E0A9B78FF/eco_data/marine_map_data/marine_map.geojson')\n",
    "# marinemap = gpd.read_file(\n",
    "#     '/media/muskrat/060A9B8E0A9B78FF/map_final/eco_map.geojson')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    " \n",
    "\n",
    "\n",
    "ranger = [*range(826, 826+232)]\n",
    "ranger2 = [*range(1058, 1058+37)]\n",
    "ranger3 = ranger2 + ranger\n",
    "marine_ids = [str(x) for x in ranger3]\n",
    "\n",
    "marinemap.insert(0, 'unique_id', marine_ids)\n",
    "\n",
    " \n",
    "\n",
    "marinemap.to_file(\"marine_map.geojson\", driver='GeoJSON')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    " \n",
    "\n",
    "\n",
    "ecomap['name'] = ecomap['ECO_NAME']\n",
    "\n",
    "ecomap[\"unique_id\"] = ecomap[\"unique_id\"].astype(\"float32\")\n",
    "\n",
    "ecomap.drop(ecomap[ecomap['unique_id'].isna()].index, inplace=True)\n",
    "\n",
    "ecomap[\"unique_id\"] = ecomap[\"unique_id\"].astype(\"int32\")\n",
    "\n",
    "ecomap['unique_id'] = ecomap['unique_id'].apply(str)\n",
    "\n",
    "ecomap.drop_duplicates(subset=['unique_id'], keep='first', inplace=True)\n",
    "\n",
    "marinemap['name'] = ''\n",
    "\n",
    "marinemap.loc[marinemap['TYPE'] == 'PPOW', 'name'] = marinemap['PROVINC']\n",
    "\n",
    "marinemap.loc[marinemap['TYPE'] == 'MEOW', 'name'] = marinemap['ECOREGION']\n",
    "\n",
    "econames = pd.concat([ecomap[['unique_id', 'name']], marinemap[[\n",
    "                     'unique_id', 'name']]], axis=0, keys=['unique_id', 'name'])\n",
    "\n",
    "\n",
    "# econames.drop_duplicates(subset=['unique_id'], keep='first', inplace=True)\n",
    "\n",
    "econames.reset_index(drop=True, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    " \n",
    "ecokeys = econames.to_json(orient='records', force_ascii=False)\n",
    "repr(ecokeys)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    " \n",
    "\n",
    "file = open(\"ecoregion_keys.json\", \"w\")\n",
    "file.write(ecokeys)\n",
    "file.close"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "eco",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
