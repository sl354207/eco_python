{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import vaex\n",
    "import numpy as np\n",
    "\n",
    "pd.set_option(\"display.max_columns\", None)\n",
    "pd.set_option(\"display.max_rows\", None)\n",
    "# pd.set_option('display.max_columns', None)\n",
    "# pd.set_option('display.width', None)\n",
    "# pd.set_option('display.max_colwidth', None)\n",
    "\n",
    "# 400 meter coordinate accuracy\n",
    "# 1923 earliest year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in obis_essential\n",
    "df_path = input(\"Enter the file path: \")\n",
    "\n",
    "df = vaex.open(df_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.dropna(\n",
    "    column_names=[\n",
    "        \"decimalLatitude\",\n",
    "        \"decimalLongitude\",\n",
    "        \"coordinateUncertaintyInMeters\",\n",
    "        \"geodeticDatum\",\n",
    "        \"species\",\n",
    "        \"date_year\",\n",
    "        \"basisOfRecord\",\n",
    "    ]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.geodeticDatum.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[\n",
    "    df.geodeticDatum.isin(\n",
    "        [\"EPSG:4326\", \"EPSG:4326 WGS84\", \"EPSG: 4326 WGS 84\", \"WGS84_EPSG:4326\"]\n",
    "    )\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find unique years in df\n",
    "years = df[\"date_year\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for some reason have to extract to new df to continue filtering\n",
    "df = df.extract()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"date_year\"] = df[\"date_year\"].astype(\"float32\")\n",
    "\n",
    "df[\"coordinateUncertaintyInMeters\"] = df[\"coordinateUncertaintyInMeters\"].astype(\n",
    "    \"float32\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[df.date_year >= 1923]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_year = df[\"date_year\"].max()\n",
    "\n",
    "min_year = df[\"date_year\"].min()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[df.coordinateUncertaintyInMeters <= 400]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_meter = df[\"coordinateUncertaintyInMeters\"].max()\n",
    "\n",
    "min_meter = df[\"coordinateUncertaintyInMeters\"].min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "basis = df[\"basisOfRecord\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[df.basisOfRecord.isin([\"HumanObservation\", \"MachineObservation\", \"Occurrence\"])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"basisOfRecord\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"flags\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[\n",
    "    \"kingdom\",\n",
    "    \"phylum\",\n",
    "    \"class\",\n",
    "    \"order\",\n",
    "    \"family\",\n",
    "    \"genus\",\n",
    "    \"species\",\n",
    "    \"decimalLatitude\",\n",
    "    \"decimalLongitude\",\n",
    "    \"license\",\n",
    "    \"rightsHolder\",\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "species_unique = df.species.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "species_values = np.array([len(word.split()) for word in species_unique])\n",
    "\n",
    "# find the max value in species_values\n",
    "max_value = np.max(species_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if value at index i in species_values is greater than 2, add the value at the same index in species_unique to a new list\n",
    "species_2 = []\n",
    "for i in range(len(species_values)):\n",
    "    if species_values[i] > 2:\n",
    "        species_2.append(species_unique[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove values from species that are greater than 2\n",
    "\n",
    "for i in range(len(species_2)):\n",
    "    df = df[df.species != species_2[i]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.extract()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# recheck\n",
    "species_unique = df[\"species\"].unique()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "species_values = np.array([len(word.split()) for word in species_unique])\n",
    "\n",
    "\n",
    "max_value = np.max(species_values)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check for strange x at beginning of species names and remove if necessary\n",
    "\n",
    "# df = df[\n",
    "#     ~df.species.isin([\"×Elyhordeum schaackianum\", \"×Elyleymus aleuticus\"])\n",
    "# ]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# REMOVE VALUES FROM SPECIES WHOSE SCIENTIFIC NAME HAS A 1 CHARACTER WORD AS SECOND WORD\n",
    "\n",
    "# use regex to determine if second word in string is 1 character long\n",
    "# \\b(\\w+)\\s(\\w{1})$\n",
    "\n",
    "\n",
    "# CHECK FOR NON LETTER CHARACTERS IN SCIENTIFIC NAME AND COMMON NAME (AND REMOVE?)\n",
    "\n",
    "# [^A-Za-z\\s] (possibly exlude dash as well by adding - after s in regex)\n",
    "# also specifically check for [] and () in common names\n",
    "# [[\\[\\]()]\n",
    "\n",
    "# CHECK FOR AND REMOVE? SCIENTIFIC NAME THAT CONTAINS SP- IN IT\n",
    "# sp-"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"license\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "license = df[\"license\"].unique()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "license_removal = [\n",
    "    \"Copyright Frank Garita Alpízar. No use without permission.\",\n",
    "    \"Copyright Ma. Eugenia Rodríguez Vázquez. No use without permission.\",\n",
    "    \"Copyright Whales of Guerrero (contact: Katherina Audley). No use without permission.\",\n",
    "    \"Copyright Rémi Bigonneau. No use without permission.\",\n",
    "    \"Copyright Nico Ransome. No use without permission.\",\n",
    "    \"Copyright Russian Cetacean Habitat Project. No use without permission.\",\n",
    "    \"Copyright Jodi Frediani. No use without permission.\",\n",
    "    \"Copyright Adam A. Pack. No use without permission.\",\n",
    "    \"Copyright Tory Kallman. No use without permission.\",\n",
    "    \"Copyright Tasli Shaw. No use without permission.\",\n",
    "    \"Copyright Amy Kennedy. No use without permission.\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(license_removal)):\n",
    "    df = df[df.license != license_removal[i]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.extract()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"license\"].value_counts()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read cleaned df into a parquet file where user can input the file path\n",
    "df_clean_path = input(\"Enter the file path: \")\n",
    "df.export_parquet(df_clean_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "eco",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
