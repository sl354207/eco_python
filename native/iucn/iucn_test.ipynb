{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopandas as gpd\n",
    "\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter by origin code 1(native) or 2 (reintroduced to native range)\n",
    "# filter by presence code 1 (present/extant)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zip = \"/media/muskrat/T7 Shield/eco_data/v3/native/IUCN/BONEFISH_TARPONS.zip\"\n",
    "\n",
    "df = gpd.read_file(zip)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print length of dataframe\n",
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# some are Shape_Leng and Shape_Area instead of SHAPE_Leng and SHAPE_Area\n",
    "# if df contains columns SHAPE_Leng and SHAPE_Area, rename them to Shape_Leng and Shape_Area\n",
    "if \"SHAPE_Leng\" in df.columns and \"SHAPE_Area\" in df.columns:\n",
    "    df = df.rename(columns={\"SHAPE_Leng\": \"Shape_Leng\", \"SHAPE_Area\": \"Shape_Area\"})\n",
    "\n",
    "df = df.drop(\n",
    "    columns=[\n",
    "        \"id_no\",\n",
    "        \"seasonal\",\n",
    "        \"compiler\",\n",
    "        \"yrcompiled\",\n",
    "        \"subspecies\",\n",
    "        \"subpop\",\n",
    "        \"Shape_Leng\",\n",
    "        \"Shape_Area\",\n",
    "        \"source\",\n",
    "        \"island\",\n",
    "        \"tax_comm\",\n",
    "        \"dist_comm\",\n",
    "        \"generalisd\",\n",
    "        \"legend\",\n",
    "    ]\n",
    ")\n",
    "\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(\n",
    "    columns=[\n",
    "        \"citation\",\n",
    "        \"category\",\n",
    "        \"marine\",\n",
    "        \"terrestial\",\n",
    "        \"freshwater\",\n",
    "        \"kingdom\",\n",
    "        \"phylum\",\n",
    "        \"class\",\n",
    "        \"order_\",\n",
    "        \"family\",\n",
    "        \"genus\",\n",
    "    ]\n",
    ")\n",
    "\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print unique values in presence column\n",
    "df[\"presence\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove rows of df where column 'presence' is not 1 or 2\n",
    "df = df[df[\"presence\"].isin([1, 2])]\n",
    "\n",
    "df[\"presence\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove rows of df where column 'origin' is not 1\n",
    "df = df[df[\"origin\"].isin([1])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create new df sci_df with columns 'sci_name', 'presence', and 'origin'\n",
    "sci_df = df[[\"sci_name\", \"presence\", \"origin\"]]\n",
    "\n",
    "sci_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.to_crs(\"EPSG:4326\")\n",
    "\n",
    "df.crs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_species = df[\"sci_name\"].unique().tolist()\n",
    "\n",
    "len(unique_species)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove items in unique_species that contain more than 2 words\n",
    "unique_species = [x for x in unique_species if len(x.split()) < 3]\n",
    "\n",
    "len(unique_species), unique_species"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sort unique_species alphabetically\n",
    "unique_species.sort()\n",
    "\n",
    "unique_species"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0, len(unique_species), 1):\n",
    "    species = unique_species[i]\n",
    "    species_df = df[df[\"sci_name\"] == species]\n",
    "    print(species_df)\n",
    "\n",
    "    # overlay = gpd.overlay(species_df, eco_map, how=\"intersection\")\n",
    "\n",
    "    # unique_ids = list(overlay[\"unique_id\"].unique())\n",
    "\n",
    "    # eco_map_unique = eco_map[eco_map[\"unique_id\"].isin(unique_ids)]\n",
    "\n",
    "    # # remove rows with <NA> in unique_id from eco_map_unique\n",
    "\n",
    "    # eco_map_unique = eco_map_unique[eco_map_unique[\"unique_id\"] != \"<NA>\"]\n",
    "\n",
    "    # overlay = overlay[overlay[\"unique_id\"] != \"<NA>\"]\n",
    "\n",
    "    # overlay[\"area\"] = overlay.geometry.area\n",
    "\n",
    "    # overlay_areas = overlay[[\"unique_id\", \"area\"]].groupby(\"unique_id\").sum()\n",
    "\n",
    "    # eco_map_unique[\"area\"] = eco_map_unique.geometry.area\n",
    "\n",
    "    # eco_map_unique_areas = (\n",
    "    #     eco_map_unique[[\"unique_id\", \"area\"]].groupby(\"unique_id\").sum()\n",
    "    # )\n",
    "\n",
    "    # combined_areas = pd.concat([overlay_areas, eco_map_unique_areas], axis=1)\n",
    "    # combined_areas.columns = [\"overlay_area\", \"eco_map_unique_area\"]\n",
    "\n",
    "    # combined_areas[\"ratio\"] = (\n",
    "    #     combined_areas[\"overlay_area\"] / combined_areas[\"eco_map_unique_area\"]\n",
    "    # )\n",
    "\n",
    "    # # keep ecoregion if only present in 1 area\n",
    "    # if len(combined_areas) == 1:\n",
    "    #     native = unique_ids\n",
    "    # else:\n",
    "    #     # if ratio > 0.2 then add unique_id to list of ids\n",
    "    #     native = combined_areas[combined_areas[\"ratio\"] > 0.2].index.tolist()\n",
    "\n",
    "    #     if len(native) == 0:\n",
    "\n",
    "    #         native = combined_areas[\n",
    "    #             combined_areas[\"eco_map_unique_area\"] <= 2\n",
    "    #         ].index.tolist()\n",
    "\n",
    "    #         if len(native) == 0:\n",
    "    #             native = combined_areas[combined_areas[\"ratio\"] > 0.1].index.tolist()\n",
    "\n",
    "    #             if len(native) == 0:\n",
    "    #                 native = [\"check\"]\n",
    "\n",
    "    # scientific_name = species_df[\"sci_name\"].values[0]\n",
    "\n",
    "    # species_final = pd.DataFrame(\n",
    "    #     {\n",
    "    #         \"scientific_name\": scientific_name,\n",
    "    #         \"database\": \"iucn\",\n",
    "    #         \"unique_id\": native,\n",
    "    #     },\n",
    "    # )\n",
    "\n",
    "    # # groupby scientific_name\n",
    "    # species_final = (\n",
    "    #     species_final.groupby([\"scientific_name\", \"database\"])[\"unique_id\"]\n",
    "    #     .apply(list)\n",
    "    #     .reset_index()\n",
    "    # )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# put first row of df into a new dataframe\n",
    "df2 = df[df[\"sci_name\"] == \"Limnonectes hascheanus\"]\n",
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ecomap_loc = \"/media/muskrat/T7 Shield/eco_data/ecomap_final/eco_map.geojson\"\n",
    "\n",
    "eco_map = gpd.read_file(ecomap_loc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot ecomap and df on same map\n",
    "base = eco_map.plot(color=\"white\", edgecolor=\"black\")\n",
    "xmin, ymin, xmax, ymax = (90, 0, 110, 30)\n",
    "\n",
    "ax = df2.plot(ax=base, color=\"red\", alpha=0.4)\n",
    "\n",
    "# set the x and y limits of the plot to the specified bounding box coordinates\n",
    "ax.set_xlim(xmin, xmax)\n",
    "ax.set_ylim(ymin, ymax)\n",
    "# ax.invert_xaxis()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "intersects = gpd.sjoin(df2, eco_map)\n",
    "\n",
    "unique_ids = list(intersects[\"unique_id\"].unique())\n",
    "\n",
    "unique_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "overlay = gpd.overlay(df2, eco_map, how=\"intersection\")\n",
    "\n",
    "overlay_ids = list(overlay[\"unique_id\"].unique())\n",
    "\n",
    "overlay_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "overlay = gpd.overlay(df2, eco_map, how=\"intersection\")\n",
    "\n",
    "unique_ids = list(overlay[\"unique_id\"].unique())\n",
    "\n",
    "eco_map_unique = eco_map[eco_map[\"unique_id\"].isin(unique_ids)]\n",
    "\n",
    "# remove rows with <NA> in unique_id from eco_map_unique\n",
    "\n",
    "eco_map_unique = eco_map_unique[eco_map_unique[\"unique_id\"] != \"<NA>\"]\n",
    "\n",
    "overlay = overlay[overlay[\"unique_id\"] != \"<NA>\"]\n",
    "\n",
    "# overlay.plot(alpha=0.5, edgecolor=\"k\", cmap=\"tab10\")\n",
    "\n",
    "overlay[\"area\"] = overlay.geometry.area\n",
    "\n",
    "overlay_areas = overlay[[\"unique_id\", \"area\"]].groupby(\"unique_id\").sum()\n",
    "\n",
    "eco_map_unique[\"area\"] = eco_map_unique.geometry.area\n",
    "\n",
    "eco_map_unique_areas = eco_map_unique[[\"unique_id\", \"area\"]].groupby(\"unique_id\").sum()\n",
    "\n",
    "combined_areas = pd.concat([overlay_areas, eco_map_unique_areas], axis=1)\n",
    "combined_areas.columns = [\"overlay_area\", \"eco_map_unique_area\"]\n",
    "\n",
    "combined_areas[\"ratio\"] = (\n",
    "    combined_areas[\"overlay_area\"] / combined_areas[\"eco_map_unique_area\"]\n",
    ")\n",
    "\n",
    "combined_areas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# keep ecoregion if only present in 1 area\n",
    "if len(combined_areas) == 1:\n",
    "    native = unique_ids\n",
    "else:\n",
    "    # if ratio > 0.2 then add unique_id to list of ids\n",
    "    native = combined_areas[combined_areas[\"ratio\"] > 0.2].index.tolist()\n",
    "\n",
    "    if len(native) == 0:\n",
    "\n",
    "        native = combined_areas[\n",
    "            combined_areas[\"eco_map_unique_area\"] <= 2\n",
    "        ].index.tolist()\n",
    "\n",
    "        if len(native) == 0:\n",
    "            native = combined_areas[combined_areas[\"ratio\"] > 0.1].index.tolist()\n",
    "\n",
    "            if len(native) == 0:\n",
    "                native = [\"check\"]\n",
    "\n",
    "native"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scientific_name = df2[\"sci_name\"].values[0]\n",
    "\n",
    "\n",
    "final = pd.DataFrame(\n",
    "    {\n",
    "        \"scientific_name\": scientific_name,\n",
    "        \"database\": \"iucn\",\n",
    "        \"unique_id\": native,\n",
    "    },\n",
    ")\n",
    "\n",
    "# groupby scientific_name\n",
    "final = (\n",
    "    final.groupby([\"scientific_name\", \"database\"])[\"unique_id\"]\n",
    "    .apply(list)\n",
    "    .reset_index()\n",
    ")\n",
    "\n",
    "\n",
    "final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sci_name = df2[\"sci_name\"].values[0]\n",
    "native = pd.DataFrame({\"sci_name\": sci_name, \"unique_id\": native})\n",
    "\n",
    "\n",
    "native"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# groupby scientific_name\n",
    "native = native.groupby([\"sci_name\"])[\"unique_id\"].apply(list).reset_index()\n",
    "\n",
    "native"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge native with df2\n",
    "df2 = pd.merge(df2, native, on=\"sci_name\")\n",
    "\n",
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = df2.drop(columns=[\"presence\", \"origin\", \"geometry\"])\n",
    "\n",
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rename sci_name to scientific_name and order_ to order\n",
    "\n",
    "df2 = df2.rename(columns={\"sci_name\": \"scientific_name\", \"order_\": \"order\"})\n",
    "\n",
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zip = input(\"Enter the zip file path: \")\n",
    "\n",
    "df = gpd.read_file(zip)\n",
    "\n",
    "ecomap_loc = input(\"Enter the ecomap file path: \")\n",
    "\n",
    "eco_map = gpd.read_file(ecomap_loc)\n",
    "\n",
    "# some are Shape_Leng and Shape_Area instead of SHAPE_Leng and SHAPE_Area\n",
    "# if df contains columns SHAPE_Leng and SHAPE_Area, rename them to Shape_Leng and Shape_Area\n",
    "if \"SHAPE_Leng\" in df.columns:\n",
    "    df = df.rename(columns={\"SHAPE_Leng\": \"Shape_Leng\"})\n",
    "\n",
    "if \"SHAPE_Area\" in df.columns:\n",
    "    df = df.rename(columns={\"SHAPE_Area\": \"Shape_Area\"})\n",
    "\n",
    "\n",
    "df = df.drop(\n",
    "    columns=[\n",
    "        \"id_no\",\n",
    "        \"seasonal\",\n",
    "        \"compiler\",\n",
    "        \"yrcompiled\",\n",
    "        \"subspecies\",\n",
    "        \"subpop\",\n",
    "        \"Shape_Leng\",\n",
    "        \"Shape_Area\",\n",
    "        \"source\",\n",
    "        \"island\",\n",
    "        \"tax_comm\",\n",
    "        \"dist_comm\",\n",
    "        \"generalisd\",\n",
    "        \"legend\",\n",
    "    ]\n",
    ")\n",
    "\n",
    "# remove rows of df where column 'presence' is not 1 or 2\n",
    "df = df[df[\"presence\"].isin([1, 2])]\n",
    "\n",
    "# remove rows of df where column 'origin' is not 1\n",
    "df = df[df[\"origin\"].isin([1])]\n",
    "\n",
    "df = df.to_crs(\"EPSG:4326\")\n",
    "\n",
    "unique_species = df[\"sci_name\"].unique().tolist()\n",
    "\n",
    "# remove items in unique_species that contain more than 2 words\n",
    "unique_species = [x for x in unique_species if len(x.split()) < 3]\n",
    "\n",
    "final = pd.DataFrame()\n",
    "for species in unique_species:\n",
    "    species_df = df[df[\"sci_name\"] == species]\n",
    "\n",
    "    intersects = gpd.sjoin(species_df, eco_map)\n",
    "\n",
    "    unique_ids = list(intersects[\"unique_id\"].unique())\n",
    "\n",
    "    eco_map_unique = eco_map[eco_map[\"unique_id\"].isin(unique_ids)]\n",
    "\n",
    "    # remove rows with <NA> in unique_id from eco_map_unique\n",
    "\n",
    "    eco_map_unique = eco_map_unique[eco_map_unique[\"unique_id\"] != \"<NA>\"]\n",
    "\n",
    "    overlay = gpd.overlay(species_df, eco_map, how=\"intersection\")\n",
    "\n",
    "    overlay = overlay[overlay[\"unique_id\"] != \"<NA>\"]\n",
    "\n",
    "    # overlay.plot(alpha=0.5, edgecolor=\"k\", cmap=\"tab10\")\n",
    "\n",
    "    overlay[\"area\"] = overlay.geometry.area\n",
    "\n",
    "    overlay_areas = overlay[[\"unique_id\", \"area\"]].groupby(\"unique_id\").sum()\n",
    "\n",
    "    eco_map_unique[\"area\"] = eco_map_unique.geometry.area\n",
    "\n",
    "    eco_map_unique_areas = (\n",
    "        eco_map_unique[[\"unique_id\", \"area\"]].groupby(\"unique_id\").sum()\n",
    "    )\n",
    "\n",
    "    combined_areas = pd.concat([overlay_areas, eco_map_unique_areas], axis=1)\n",
    "    combined_areas.columns = [\"overlay_area\", \"eco_map_unique_area\"]\n",
    "\n",
    "    combined_areas[\"percentage\"] = (\n",
    "        combined_areas[\"overlay_area\"] / combined_areas[\"eco_map_unique_area\"]\n",
    "    )\n",
    "\n",
    "    # combined_areas\n",
    "\n",
    "    # keep ecoregion if only present in 1 area\n",
    "    if len(combined_areas) == 1:\n",
    "        native = unique_ids\n",
    "    else:\n",
    "        # if overlay_area / eco_map_unique_area > 0.2 then add unique_id to list of ids\n",
    "        native = combined_areas[\n",
    "            combined_areas[\"overlay_area\"] / combined_areas[\"eco_map_unique_area\"] > 0.2\n",
    "        ].index.tolist()\n",
    "\n",
    "        if len(native) == 0:\n",
    "\n",
    "            native = combined_areas[\n",
    "                combined_areas[\"eco_map_unique_area\"] <= 2\n",
    "            ].index.tolist()\n",
    "\n",
    "            if len(native) == 0:\n",
    "                native = combined_areas[\n",
    "                    combined_areas[\"overlay_area\"]\n",
    "                    / combined_areas[\"eco_map_unique_area\"]\n",
    "                    > 0.1\n",
    "                ].index.tolist()\n",
    "\n",
    "                if len(native) == 0:\n",
    "                    native = [\"check\"]\n",
    "\n",
    "    scientific_name = species_df[\"sci_name\"].values[0]\n",
    "\n",
    "    native_df = pd.DataFrame({\"sci_name\": scientific_name, \"unique_id\": native})\n",
    "\n",
    "    native_df = native_df.groupby([\"sci_name\"])[\"unique_id\"].apply(list).reset_index()\n",
    "\n",
    "    species_final = pd.merge(species_df, native_df, on=\"sci_name\")\n",
    "\n",
    "    species_final = species_final.drop(columns=[\"presence\", \"origin\", \"geometry\"])\n",
    "\n",
    "    species_final = species_final.rename(\n",
    "        columns={\"sci_name\": \"scientific_name\", \"order_\": \"order\"}\n",
    "    )\n",
    "\n",
    "    final = pd.concat([final, species_final], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_path = input(\"Enter the file path: \")\n",
    "\n",
    "final.to_parquet(final_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "eco",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
