{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopandas as gpd\n",
    "\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "meta_input = input(\"Enter the file path: \")\n",
    "\n",
    "metadata = pd.read_csv(\n",
    "    meta_input,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata.head(40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find row where SHP/* equals acoewrig\n",
    "row = metadata[metadata[\"SHP/*\"] == \"acoewrig\"].index[0]\n",
    "\n",
    "row\n",
    "\n",
    "sliice = metadata.iloc[row:, :]\n",
    "\n",
    "sliice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create new dataframe with latin names, common names, and shp/* columns from metadata\n",
    "\n",
    "metadata = metadata[[\"Latin Name\", \"Common Name\", \"SHP/*\"]]\n",
    "\n",
    "metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "little = gpd.read_file(\n",
    "    \"/media/muskrat/T7 Shield/eco_data/v3/native/little/7445016/wpetry/USTreeAtlas-v1.0/wpetry-USTreeAtlas-4999258/geojson/alnumari.geojson\"\n",
    ")\n",
    "\n",
    "little"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "little.crs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "little = little.to_crs(\"EPSG:4326\")\n",
    "\n",
    "little.crs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "little.plot().invert_xaxis()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ecomap_loc = \"/media/muskrat/T7 Shield/eco_data/ecomap_final/eco_map.geojson\"\n",
    "\n",
    "eco_map = gpd.read_file(ecomap_loc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base = eco_map.plot(color=\"white\", edgecolor=\"black\")\n",
    "xmin, ymin, xmax, ymax = (-60, 25, -100, 45)\n",
    "\n",
    "ax = little.plot(ax=base, color=\"red\", alpha=0.4)\n",
    "\n",
    "# set the x and y limits of the plot to the specified bounding box coordinates\n",
    "ax.set_xlim(xmin, xmax)\n",
    "ax.set_ylim(ymin, ymax)\n",
    "ax.invert_xaxis()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "intersects = gpd.sjoin(little, eco_map)\n",
    "\n",
    "intersects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# put unique values of unique_id in intersects into a list\n",
    "\n",
    "unique_ids = list(intersects[\"unique_id\"].unique())\n",
    "unique_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create dataframe from eco_map that only contains the unique ids in unique_ids\n",
    "\n",
    "eco_map_unique = eco_map[eco_map[\"unique_id\"].isin(unique_ids)]\n",
    "eco_map_unique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove rows with <NA> in unique_id from eco_map_unique\n",
    "\n",
    "eco_map_unique = eco_map_unique[eco_map_unique[\"unique_id\"] != \"<NA>\"]\n",
    "\n",
    "# remove rows withe MEOW or PPOW in TYPE from eco_map_unique\n",
    "\n",
    "eco_map_unique = eco_map_unique[~eco_map_unique[\"TYPE\"].isin([\"MEOW\", \"PPOW\"])]\n",
    "\n",
    "eco_map_unique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eco_map_unique.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "overlay = gpd.overlay(little, eco_map, how=\"intersection\")\n",
    "\n",
    "overlay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove rows with <NA> in unique_id from overlay\n",
    "\n",
    "overlay = overlay[overlay[\"unique_id\"] != \"<NA>\"]\n",
    "\n",
    "# remove rows with MEOW or PPOW in TYPE from overlay\n",
    "\n",
    "overlay = overlay[~overlay[\"TYPE\"].isin([\"MEOW\", \"PPOW\"])]\n",
    "\n",
    "overlay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "overlay.plot(alpha=0.5, edgecolor=\"k\", cmap=\"tab10\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "overlay[\"area\"] = overlay.geometry.area\n",
    "\n",
    "overlay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a new dataframe from overlay where the first column is unique_id and the second column is the area of all the rows in overlay that have the same unique_id\n",
    "\n",
    "overlay_areas = overlay[[\"unique_id\", \"area\"]].groupby(\"unique_id\").sum()\n",
    "\n",
    "overlay_areas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add an area column to eco_map_unique dataframe\n",
    "\n",
    "eco_map_unique[\"area\"] = eco_map_unique.geometry.area\n",
    "\n",
    "eco_map_unique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a new dataframe from eco_map_unique where the first column is unique_id and the second column is the area of all the rows in eco_map_unique that have the same unique_id\n",
    "\n",
    "eco_map_unique_areas = eco_map_unique[[\"unique_id\", \"area\"]].groupby(\"unique_id\").sum()\n",
    "\n",
    "eco_map_unique_areas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# combine eco_map_unique_areas and overlay_areas into a new dataframe where the first column is unique_id, the second column is area from overlays, and the third column is area from eco_map_unique\n",
    "\n",
    "combined_areas = pd.concat([overlay_areas, eco_map_unique_areas], axis=1)\n",
    "combined_areas.columns = [\"overlay_area\", \"eco_map_unique_area\"]\n",
    "\n",
    "combined_areas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_areas[\"percentage\"] = (\n",
    "    combined_areas[\"overlay_area\"] / combined_areas[\"eco_map_unique_area\"]\n",
    ")\n",
    "\n",
    "combined_areas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if overlay_area / eco_map_unique_area > 0.2 then add unique_id to list of ids\n",
    "\n",
    "# if length of combined_areas == 1 then native = unique_ids\n",
    "\n",
    "if len(combined_areas) == 1:\n",
    "    native = unique_ids\n",
    "else:\n",
    "\n",
    "    native = combined_areas[\n",
    "        combined_areas[\"overlay_area\"] / combined_areas[\"eco_map_unique_area\"] > 0.2\n",
    "    ].index.tolist()\n",
    "\n",
    "    print(len(native))\n",
    "\n",
    "    if len(native) == 0:\n",
    "        print(\"test\")\n",
    "        native = combined_areas[\n",
    "            combined_areas[\"eco_map_unique_area\"] <= 2\n",
    "        ].index.tolist()\n",
    "        print(native)\n",
    "        if len(native) == 0:\n",
    "            native = combined_areas[\n",
    "                combined_areas[\"overlay_area\"] / combined_areas[\"eco_map_unique_area\"]\n",
    "                > 0.1\n",
    "            ].index.tolist()\n",
    "            print(native)\n",
    "\n",
    "native\n",
    "\n",
    "native_df = eco_map[eco_map[\"unique_id\"].isin(native)]\n",
    "\n",
    "native_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "native_df = eco_map[eco_map[\"unique_id\"].isin(native)]\n",
    "\n",
    "native_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "native_df.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scientific_name equals the Latin Name in metadata at value of SHP/*\n",
    "\n",
    "scientific_name = metadata.loc[metadata[\"SHP/*\"] == \"acacchor\"][\"Latin Name\"].values[0]\n",
    "\n",
    "\n",
    "common_name = metadata.loc[metadata[\"SHP/*\"] == \"acacchor\"][\"Common Name\"].values[0]\n",
    "\n",
    "# final dataframe\n",
    "\n",
    "final = pd.DataFrame(\n",
    "    {\n",
    "        \"scientific_name\": scientific_name,\n",
    "        \"common_name\": common_name,\n",
    "        \"unique_id\": native,\n",
    "    },\n",
    ")\n",
    "\n",
    "\n",
    "# groupby scientific_name\n",
    "final = (\n",
    "    final.groupby([\"scientific_name\", \"common_name\"])[\"unique_id\"]\n",
    "    .apply(list)\n",
    "    .reset_index()\n",
    ")\n",
    "\n",
    "final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write to parquet file\n",
    "\n",
    "# path equals scientific_name from final without spaces and converted to string\n",
    "\n",
    "string_name = str(final[\"scientific_name\"].values[0]).replace(\" \", \"_\")\n",
    "\n",
    "base_path = input(\"Enter the base path: \")\n",
    "\n",
    "path = base_path + string_name + \".parquet\"\n",
    "\n",
    "final.to_parquet(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "little_base = input(\"Enter the little base file path: \")\n",
    "\n",
    "final_base_path = input(\"Enter the final base path: \")\n",
    "\n",
    "for shp in metadata[\"SHP/*\"]:\n",
    "    print(shp)\n",
    "    path = f\"{little_base}{shp}.geojson\"\n",
    "\n",
    "    little = gpd.read_file(\n",
    "        path,\n",
    "    )\n",
    "\n",
    "    # convert crs\n",
    "    little = little.to_crs(\"EPSG:4326\")\n",
    "\n",
    "    # find intersecting geometry\n",
    "    intersects = gpd.sjoin(little, eco_map)\n",
    "\n",
    "    # put unique values of unique_id in intersects into a list\n",
    "    unique_ids = list(intersects[\"unique_id\"].unique())\n",
    "\n",
    "    # create dataframe from eco_map that only contains the unique ids in unique_ids\n",
    "    eco_map_unique = eco_map[eco_map[\"unique_id\"].isin(unique_ids)]\n",
    "\n",
    "    # remove rows with <NA> in unique_id from eco_map_unique\n",
    "    eco_map_unique = eco_map_unique[eco_map_unique[\"unique_id\"] != \"<NA>\"]\n",
    "\n",
    "    # find overlaying geometry\n",
    "    overlay = gpd.overlay(little, eco_map, how=\"intersection\")\n",
    "\n",
    "    # remove rows with <NA> in unique_id from overlay\n",
    "    overlay = overlay[overlay[\"unique_id\"] != \"<NA>\"]\n",
    "\n",
    "    # add area column to overlay\n",
    "    overlay[\"area\"] = overlay.geometry.area\n",
    "\n",
    "    # create a new dataframe from overlay where the first column is unique_id and the second column is the area of all the rows in overlay that have the same unique_id\n",
    "    overlay_areas = overlay[[\"unique_id\", \"area\"]].groupby(\"unique_id\").sum()\n",
    "\n",
    "    # add an area column to eco_map_unique dataframe\n",
    "    eco_map_unique[\"area\"] = eco_map_unique.geometry.area\n",
    "\n",
    "    # create a new dataframe from eco_map_unique where the first column is unique_id and the second column is the area of all the rows in eco_map_unique that have the same unique_id\n",
    "    eco_map_unique_areas = (\n",
    "        eco_map_unique[[\"unique_id\", \"area\"]].groupby(\"unique_id\").sum()\n",
    "    )\n",
    "\n",
    "    # combine eco_map_unique_areas and overlay_areas into a new dataframe where the first column is unique_id, the second column is area from overlays, and the third column is area from eco_map_unique\n",
    "    combined_areas = pd.concat([overlay_areas, eco_map_unique_areas], axis=1)\n",
    "    combined_areas.columns = [\"overlay_area\", \"eco_map_unique_area\"]\n",
    "\n",
    "    # if overlay_area / eco_map_unique_area > 0.2 then add unique_id to list of ids\n",
    "    native = combined_areas[\n",
    "        combined_areas[\"overlay_area\"] / combined_areas[\"eco_map_unique_area\"] > 0.2\n",
    "    ].index.tolist()\n",
    "\n",
    "    # convert to df\n",
    "    native_df = eco_map[eco_map[\"unique_id\"].isin(native)]\n",
    "\n",
    "    # scientific_name equals the Latin Name in metadata at value of SHP/*\n",
    "    scientific_name = metadata.loc[metadata[\"SHP/*\"] == shp][\"Latin Name\"].values[0]\n",
    "    print(scientific_name)\n",
    "\n",
    "    common_name = metadata.loc[metadata[\"SHP/*\"] == shp][\"Common Name\"].values[0]\n",
    "    print(common_name)\n",
    "    # final dataframe\n",
    "    final = pd.DataFrame(\n",
    "        {\n",
    "            \"scientific_name\": scientific_name,\n",
    "            \"common_name\": common_name,\n",
    "            \"unique_id\": native,\n",
    "        },\n",
    "    )\n",
    "\n",
    "    # groupby scientific_name\n",
    "    final = (\n",
    "        final.groupby([\"scientific_name\", \"common_name\"])[\"unique_id\"]\n",
    "        .apply(list)\n",
    "        .reset_index()\n",
    "    )\n",
    "\n",
    "    print(final)\n",
    "\n",
    "    string_name = str(final[\"scientific_name\"].values[0]).replace(\" \", \"_\")\n",
    "\n",
    "    path = final_base_path + string_name + \".parquet\"\n",
    "    print(path)\n",
    "\n",
    "    final.to_parquet(path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "eco",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
