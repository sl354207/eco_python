{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopandas as gpd\n",
    "\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parq = gpd.read_parquet(\n",
    "    \"/media/muskrat/T7 Shield/eco_data/v3/native/GAP/init/4500.parquet\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove duplicates from parq\n",
    "\n",
    "parq = parq.drop_duplicates(subset=[\"intGapOrigin\", \"geometry\"])\n",
    "\n",
    "parq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# species dataframe = group by scientific name \"Lithobates catesbeianus\" parq\n",
    "\n",
    "# species = parq[parq[\"scientific_name\"] == \"Lithobates catesbeianus\"]\n",
    "\n",
    "# species"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_species = parq[\"scientific_name\"].unique().tolist()\n",
    "\n",
    "unique_species"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove items in unique_species that contain more than 2 words\n",
    "\n",
    "unique_species = [x for x in unique_species if len(x.split()) < 3]\n",
    "\n",
    "unique_species"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split species into dataframes based on how many rows they have\n",
    "singles = pd.DataFrame()\n",
    "multiples = pd.DataFrame()\n",
    "for species in unique_species:\n",
    "    species_df = parq[parq[\"scientific_name\"] == species]\n",
    "\n",
    "    origin_list = species_df[\"intGapOrigin\"].tolist()\n",
    "    unique_origin = set(origin_list)\n",
    "\n",
    "    presence_list = species_df[\"intGapPres\"].tolist()\n",
    "    unique_presence = set(presence_list)\n",
    "\n",
    "    # # only keep if 1 row and intGapOrigin is 1(native)\n",
    "    if len(species_df) == 1 and unique_origin == {1} and unique_presence == {1}:\n",
    "        singles = singles.append(species_df)\n",
    "    # only keep if more than 1 row and unique_list contains 1\n",
    "    elif len(species_df) > 1 and 1 in unique_origin and 1 in unique_presence:\n",
    "        multiples = multiples.append(species_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "singles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "multiples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "multiples_species_unique = multiples[\"scientific_name\"].unique().tolist()\n",
    "\n",
    "# split multiples into dataframes based on if they are all native or native and non-native\n",
    "multiples_native = pd.DataFrame()\n",
    "multiples_non_native = pd.DataFrame()\n",
    "\n",
    "for species in multiples_species_unique:\n",
    "    species_df = multiples[multiples[\"scientific_name\"] == species]\n",
    "\n",
    "    list = species_df[\"intGapOrigin\"].tolist()\n",
    "    # if list contains value other than 1, then append to multiples_non_native\n",
    "    unique_list = set(list)\n",
    "    if len(unique_list) > 1:\n",
    "        multiples_non_native = multiples_non_native.append(species_df)\n",
    "    else:\n",
    "        multiples_native = multiples_native.append(species_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "multiples_native"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "multiples_non_native"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = multiples_non_native[\n",
    "#     multiples_non_native[\"scientific_name\"] == \"Lithobates catesbeianus\"\n",
    "# ]\n",
    "\n",
    "# df[0:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# concat singles and multiples_native\n",
    "\n",
    "clean = pd.concat([singles, multiples_native])\n",
    "\n",
    "clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop rows where intGapOrigin is not 1\n",
    "\n",
    "clean = clean[clean[\"intGapOrigin\"] == 1]\n",
    "\n",
    "# drop columns intGapPres, intGapRepro, intGapSeas\n",
    "\n",
    "clean = clean.drop(\n",
    "    columns=[\"intGapPres\", \"intGapRepro\", \"intGapSeas\", \"Reproduction\", \"Season\"]\n",
    ")\n",
    "\n",
    "clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean.to_parquet(\n",
    "    \"/media/muskrat/T7 Shield/eco_data/v3/native/GAP/clean/4500_pre_clean.parquet\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "multiples_non_native.to_parquet(\n",
    "    \"/media/muskrat/T7 Shield/eco_data/v3/native/GAP/clean/4500_check.parquet\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter by intGapOrigin = 1 (native) (and Origin = Native for double check) and intGapPres = 1 (present) (and Presence = Known/extant for double check)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.crs\n",
    "\n",
    "# check units\n",
    "# df.crs.axis_info[0].unit_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# converts crs to epsg:4326\n",
    "df = df.to_crs(\"EPSG:4326\")\n",
    "df.crs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ecomap_loc = \"/media/muskrat/T7 Shield/eco_data/ecomap_final/eco_map.geojson\"\n",
    "\n",
    "eco_map = gpd.read_file(ecomap_loc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eco_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eco_map.crs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert df to geodataframe maybe not needed\n",
    "df = gpd.GeoDataFrame(df, geometry=\"geometry\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot ecomap and df on same map\n",
    "base = eco_map.plot(color=\"white\", edgecolor=\"black\")\n",
    "xmin, ymin, xmax, ymax = (-120, 30, -100, 45)\n",
    "\n",
    "ax = df.plot(ax=base, color=\"red\", alpha=0.4)\n",
    "\n",
    "# set the x and y limits of the plot to the specified bounding box coordinates\n",
    "ax.set_xlim(xmin, xmax)\n",
    "ax.set_ylim(ymin, ymax)\n",
    "# plot the GeoDataFrame with the specified bounding box\n",
    "# df.plot(ax=base, color='red', extent=[xmin, xmax, ymin, ymax])\n",
    "\n",
    "# df.plot(ax=base, color='red')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check if df geometry intersects with ecomap geometry\n",
    "\n",
    "intersects = gpd.sjoin(df, eco_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "intersects.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# put unique values of unique_id in intersects into a list\n",
    "\n",
    "unique_ids = list(intersects[\"unique_id\"].unique())\n",
    "unique_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create dataframe from eco_map that only contains the unique ids in unique_ids\n",
    "\n",
    "eco_map_unique = eco_map[eco_map[\"unique_id\"].isin(unique_ids)]\n",
    "# eco_map_unique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eco_map_unique.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "overlay = gpd.overlay(df, eco_map, how=\"intersection\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "overlay.plot(alpha=0.5, edgecolor=\"k\", cmap=\"tab10\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "overlay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "o_area = overlay.area.sum()\n",
    "\n",
    "o_area"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add area column to overlay dataframe\n",
    "\n",
    "overlay[\"area\"] = overlay.geometry.area"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find row with max area in overlay dataframe\n",
    "\n",
    "overlay.loc[overlay[\"area\"].idxmax()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print overlay row\n",
    "\n",
    "overlay.iloc[6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a new dataframe from overlay where the first column is unique_id and the second column is the area of all the rows in overlay that have the same unique_id\n",
    "\n",
    "overlay_areas = overlay[[\"unique_id\", \"area\"]].groupby(\"unique_id\").sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "overlay_areas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add an area column to eco_map_unique dataframe\n",
    "\n",
    "eco_map_unique[\"area\"] = eco_map_unique.geometry.area"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a new dataframe from eco_map_unique where the first column is unique_id and the second column is the area of all the rows in eco_map_unique that have the same unique_id\n",
    "\n",
    "eco_map_unique_areas = eco_map_unique[[\"unique_id\", \"area\"]].groupby(\"unique_id\").sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eco_map_unique_areas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# combine eco_map_unique_areas and overlay_areas into a new dataframe where the first column is unique_id, the second column is area from overlays, and the third column is area from eco_map_unique\n",
    "\n",
    "combined_areas = pd.concat([overlay_areas, eco_map_unique_areas], axis=1)\n",
    "combined_areas.columns = [\"overlay_area\", \"eco_map_unique_area\"]\n",
    "\n",
    "combined_areas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if overlay_area / eco_map_unique_area > 0.2 then add unique_id to list of ids\n",
    "\n",
    "native = combined_areas[\n",
    "    combined_areas[\"overlay_area\"] / combined_areas[\"eco_map_unique_area\"] > 0.2\n",
    "].index.tolist()\n",
    "\n",
    "native"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# inter_repro = intersects.to_crs(\"EPSG:6933\")\n",
    "\n",
    "# inter_repro.crs.axis_info[0].unit_name"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "eco",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
