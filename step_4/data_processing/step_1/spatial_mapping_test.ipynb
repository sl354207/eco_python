{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 400 meter coordinate accuracy\n",
    "# 1924 earliest year\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "\n",
    "# from dask import dataframe as dd\n",
    "\n",
    "# import dask_geopandas\n",
    "\n",
    "pd.set_option(\"display.max_columns\", None)\n",
    "# pd.set_option('display.max_rows', None)\n",
    "# pd.set_option('display.max_columns', None)\n",
    "# pd.set_option('display.width', None)\n",
    "# pd.set_option('display.max_colwidth', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in cleaned parquet\n",
    "df_path = input(\"Enter the file path: \")\n",
    "\n",
    "# df = dd.read_parquet(df_path)\n",
    "# df = gpd.read_parquet(df_path)\n",
    "df = pd.read_parquet(df_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in eco_map.geojson\n",
    "map_path = input(\"Enter the file path: \")\n",
    "\n",
    "map = gpd.read_file(map_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "map.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "map.crs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = gpd.GeoDataFrame(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"geometry\"] = gpd.points_from_xy(df[\"decimalLongitude\"], df[\"decimalLatitude\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.set_geometry(\"geometry\")\n",
    "\n",
    "df = df.set_crs(\"EPSG:4326\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.crs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop([\"decimalLatitude\", \"decimalLongitude\"], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.sjoin(map, predicate=\"within\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ECOREGIONS ONLY, NO FRESHWATER OR SOIL\n",
    "# remove rows with <NA> in unique_id from df\n",
    "df = df[df[\"unique_id\"] != \"<NA>\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del map, map_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = df.drop([\"index_right\", \"geometry\", \"name\", \"TYPE\"], axis=1)\n",
    "\n",
    "# freshwater\n",
    "# df = df.drop([\"index_right\", \"geometry\", \"name\", \"rights\"], axis=1)\n",
    "\n",
    "# soil\n",
    "df = df.drop(\n",
    "    [\n",
    "        \"index_right\",\n",
    "        \"geometry\",\n",
    "        \"rights\",\n",
    "        \"dominant_soil_type_percentage\",\n",
    "        \"soil_texture\",\n",
    "        \"soil_slope\",\n",
    "        \"soil_id\",\n",
    "        \"FAOSOIL\",\n",
    "    ],\n",
    "    axis=1,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# unique_regions = (\n",
    "#     df.groupby(\"species\")\n",
    "#     .apply(\n",
    "#         lambda x: pd.Series(\n",
    "#             {\n",
    "#                 \"unique_id\": list(x[\"unique_id\"].unique()),\n",
    "#                 \"rights\": list(\n",
    "#                     x[[\"unique_id\", \"rights\"]].drop_duplicates(\n",
    "#                         \"unique_id\", keep=\"first\"\n",
    "#                     )[\"rights\"]\n",
    "#                 ),\n",
    "#             }\n",
    "#         )\n",
    "#     )\n",
    "#     .reset_index()\n",
    "# )\n",
    "\n",
    "# freshwater\n",
    "# unique_regions = (\n",
    "#     df.groupby(\"species\")\n",
    "#     .apply(\n",
    "#         lambda x: pd.Series(\n",
    "#             {\n",
    "#                 \"id\": list(x[\"id\"].unique()),\n",
    "#             }\n",
    "#         )\n",
    "#     )\n",
    "#     .reset_index()\n",
    "# )\n",
    "\n",
    "# soil\n",
    "unique_regions = (\n",
    "    df.groupby(\"species\")\n",
    "    .apply(\n",
    "        lambda x: pd.Series(\n",
    "            {\n",
    "                \"id\": list(x[\"id\"]),\n",
    "                \"specific_soil_name\": list(x[\"specific_soil_name\"]),\n",
    "                \"dominant_soil_name\": list(x[\"dominant_soil_name\"]),\n",
    "            }\n",
    "        )\n",
    "    )\n",
    "    .reset_index()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_species = df.drop_duplicates(subset=[\"species\"])\n",
    "\n",
    "# ecoregions\n",
    "# unique_species = unique_species.drop([\"unique_id\", \"rights\"], axis=1)\n",
    "\n",
    "# freshwater\n",
    "# unique_species = unique_species.drop([\"id\"], axis=1)\n",
    "\n",
    "# soil\n",
    "unique_species = unique_species.drop(\n",
    "    [\"specific_soil_name\", \"dominant_soil_name\", \"id\"], axis=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.merge(unique_regions, unique_species, on=\"species\", how=\"inner\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = df.rename(\n",
    "#     columns={\"species\": \"scientific_name\", \"unique_id\": \"observed_ecoregions\"}\n",
    "# )\n",
    "\n",
    "# freshwater\n",
    "# df = df.rename(columns={\"species\": \"scientific_name\", \"id\": \"freshwater_ecoregions\"})\n",
    "\n",
    "# soil\n",
    "df = df.rename(columns={\"species\": \"scientific_name\", \"id\": \"soil_id\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ECOREGIONS ONLY\n",
    "\n",
    "# remove None values from rights column\n",
    "df[\"rights\"] = df[\"rights\"].apply(lambda x: [i for i in x if i is not None])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_spatial_path = input(\"Enter the file path: \")\n",
    "\n",
    "\n",
    "# write df to parquet file using pandas to_parquet\n",
    "df.to_parquet(df_spatial_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "eco",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
