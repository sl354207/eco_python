{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "pd.set_option(\"display.max_columns\", None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "base_path = input(\"Enter the file base path: \")\n",
    "\n",
    "final_path = input(\"Enter the final file path: \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "files = os.listdir(base_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined = pd.DataFrame()\n",
    "\n",
    "for file in files:\n",
    "    df = pd.read_parquet(f\"{base_path}/{file}\")\n",
    "\n",
    "    combined = pd.concat([combined, df], ignore_index=True, axis=0)\n",
    "    # print(file)\n",
    "\n",
    "    # print(f'max ecoregions length is {df[\"observed_ecoregions\"].str.len().max()}')\n",
    "    # print(f'max rights length is {df[\"rights\"].str.len().max()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# REMOVE NONE VALUES FROM RIGHTS COLUMN\n",
    "# test[\"rights\"] = test[\"rights\"].apply(lambda x: [i for i in x if i is not None])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ecoregions\n",
    "\n",
    "combined_grouped = combined.groupby(\n",
    "    [\"scientific_name\", \"kingdom\", \"phylum\", \"class\", \"order\", \"family\", \"genus\"],\n",
    "    as_index=False,\n",
    "    dropna=False,\n",
    ").apply(\n",
    "    lambda x: pd.Series(\n",
    "        {\n",
    "            \"observed_ecoregions\": list(\n",
    "                [item for sublist in x[\"observed_ecoregions\"] for item in sublist]\n",
    "            ),\n",
    "            \"rights\": list([item for sublist in x[\"rights\"] for item in sublist]),\n",
    "        }\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_grouped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\n",
    "    f'max ecoregions length is {combined_grouped[\"observed_ecoregions\"].str.len().max()}'\n",
    ")\n",
    "print(f'max rights length is {combined_grouped[\"rights\"].str.len().max()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ecoregions\n",
    "# SLOW, TOOK ABOUT AN HOUR FOR 300,000+ ROWS\n",
    "for i in range(len(combined_grouped)):\n",
    "    print(f\"index: {i}\")\n",
    "    # print(len(test[\"observed_ecoregions\"].iloc[i]))\n",
    "    cat = []\n",
    "    rights_cat = []\n",
    "    for j in range(len(combined_grouped[\"observed_ecoregions\"].iloc[i])):\n",
    "        if combined_grouped[\"observed_ecoregions\"].iloc[i][j] not in cat:\n",
    "            cat.append(combined_grouped[\"observed_ecoregions\"].iloc[i][j])\n",
    "            rights_cat.append(combined_grouped[\"rights\"].iloc[i][j])\n",
    "        # print(test[\"observed_ecoregions\"].iloc[i][j])\n",
    "        # for k in test[\"observed_ecoregions\"].iloc[i][j]:\n",
    "        # print(k)\n",
    "        # if k not in cat:\n",
    "        #     cat.append(k)\n",
    "    # if len(cat) != len(test[\"observed_ecoregions\"].iloc[i]):\n",
    "    # print(f'index: {i}')\n",
    "\n",
    "    # print(f'observed: {test[\"observed_ecoregions\"].iloc[i]}')\n",
    "    # print(f'cat: {cat}')\n",
    "    if len(combined_grouped[\"rights\"].iloc[i]) != len(\n",
    "        combined_grouped[\"observed_ecoregions\"].iloc[i]\n",
    "    ):\n",
    "        print(f\"index: {i}\")\n",
    "        print(\"rights\")\n",
    "\n",
    "    combined_grouped[\"observed_ecoregions\"].iloc[i] = cat\n",
    "    combined_grouped[\"rights\"].iloc[i] = rights_cat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# freshwater\n",
    "\n",
    "combined_grouped = combined.groupby(\n",
    "    [\"scientific_name\", \"kingdom\", \"phylum\", \"class\", \"order\", \"family\", \"genus\"],\n",
    "    as_index=False,\n",
    "    dropna=False,\n",
    ").apply(\n",
    "    lambda x: pd.Series(\n",
    "        {\n",
    "            \"freshwater_ecoregions\": list(\n",
    "                set(\n",
    "                    [item for sublist in x[\"freshwater_ecoregions\"] for item in sublist]\n",
    "                )\n",
    "            ),\n",
    "        }\n",
    "    )\n",
    ")\n",
    "\n",
    "# soil\n",
    "\n",
    "# combined_grouped = combined.groupby(\n",
    "#     [\"scientific_name\", \"kingdom\", \"phylum\", \"class\", \"order\", \"family\", \"genus\"],\n",
    "#     as_index=False, dropna=False,\n",
    "# ).apply(\n",
    "#     lambda x: pd.Series(\n",
    "#         {\n",
    "#             \"soil_id\": list([item for sublist in x[\"soil_id\"] for item in sublist])\n",
    "#             \"specific_soil_name\": list(\n",
    "#                 [\n",
    "#                     item\n",
    "#                     for sublist in x[\"specific_soil_name\"]\n",
    "#                     for item in sublist\n",
    "#                     if item is not None\n",
    "#                 ]\n",
    "#             ),\n",
    "#             \"dominant_soil_name\": list(\n",
    "#                 [\n",
    "#                     item\n",
    "#                     for sublist in x[\"dominant_soil_name\"]\n",
    "#                     for item in sublist\n",
    "#                     if item is not None\n",
    "#                 ]\n",
    "#             ),\n",
    "#         }\n",
    "#     )\n",
    "# )\n",
    "# combined_grouped = combined.groupby(\n",
    "#     [\"scientific_name\", \"kingdom\", \"phylum\", \"class\", \"order\", \"family\", \"genus\"],\n",
    "#     as_index=False, dropna=False,\n",
    "# ).agg(\n",
    "#     {\n",
    "#         \"soil_id\": lambda x: list([item for sublist in x for item in sublist]),\n",
    "#     }\n",
    "# )\n",
    "\n",
    "# import dask.dataframe as dd\n",
    "\n",
    "# # create a Dask DataFrame\n",
    "# dask_df = dd.from_pandas(combined, npartitions=10)\n",
    "\n",
    "\n",
    "# def get_unique_values(group):\n",
    "#     return pd.Series(\n",
    "#         {\n",
    "#             \"soil_id\": list([item for sublist in group[\"soil_id\"] for item in sublist]),\n",
    "#             \"specific_soil_name\": list(\n",
    "#                 [item for sublist in group[\"specific_soil_name\"] for item in sublist]\n",
    "#             ),\n",
    "#             \"dominant_soil_name\": list(\n",
    "#                 [item for sublist in group[\"dominant_soil_name\"] for item in sublist]\n",
    "#             ),\n",
    "#         }\n",
    "#     )\n",
    "\n",
    "\n",
    "# combined_grouped = (\n",
    "#     dask_df.groupby(\n",
    "#         [\"scientific_name\", \"kingdom\", \"phylum\", \"class\", \"order\", \"family\", \"genus\"]\n",
    "#     )\n",
    "#     .apply(get_unique_values)\n",
    "#     .reset_index()\n",
    "#     .compute()\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "duplicates = combined_grouped[\n",
    "    combined_grouped.duplicated([\"scientific_name\"], keep=False)\n",
    "]\n",
    "\n",
    "duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_grouped.to_parquet(f\"{final_path}/combined.parquet\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "eco",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
