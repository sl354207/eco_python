{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_path = input(\"Enter the file path: \")\n",
    "\n",
    "df = pd.read_parquet(df_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reset index\n",
    "\n",
    "df = df.reset_index(drop=True)\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find duplicates in scientific_name column\n",
    "duplicates = df[df.duplicated(subset=[\"scientific_name\"], keep=False)]\n",
    "\n",
    "duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find unique values of species_type in duplicates\n",
    "df[\"species_type\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_duplicates = df[\n",
    "    df.duplicated(\n",
    "        subset=[\n",
    "            \"kingdom\",\n",
    "            \"phylum\",\n",
    "            \"class\",\n",
    "            \"order\",\n",
    "            \"family\",\n",
    "            \"genus\",\n",
    "            \"scientific_name\",\n",
    "        ],\n",
    "        keep=False,\n",
    "    )\n",
    "]\n",
    "\n",
    "full_duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# partial_duplicates equals rows in duplicates that are not in full_duplicates\n",
    "partial_duplicates = duplicates[~duplicates.index.isin(full_duplicates.index)]\n",
    "\n",
    "partial_duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "partial_duplicates = merged_duplicates\n",
    "\n",
    "partial_duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "partial_duplicates = partial_duplicates.reset_index(drop=True)\n",
    "\n",
    "partial_duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fill missing values of native_ecoregions and freshwater_ecoregions with empty list\n",
    "for i in range(len(partial_duplicates)):\n",
    "    print(i)\n",
    "    #    print(type(df_clean.loc[i, \"native_ecoregions\"]))\n",
    "    if partial_duplicates.loc[i, \"native_ecoregions\"] is None:\n",
    "        partial_duplicates.loc[i, \"native_ecoregions\"] = [None]\n",
    "    if partial_duplicates.loc[i, \"freshwater_ecoregions\"] is None:\n",
    "        partial_duplicates.loc[i, \"freshwater_ecoregions\"] = [None]\n",
    "\n",
    "\n",
    "partial_duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(partial_duplicates)):\n",
    "    print(i)\n",
    "    #    print(type(df_clean.loc[i, \"native_ecoregions\"]))\n",
    "    if partial_duplicates.loc[i, \"rights\"] is None:\n",
    "        partial_duplicates.loc[i, \"rights\"] = [None]\n",
    "\n",
    "partial_duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "partial_duplicates_grouped = partial_duplicates.groupby(\n",
    "    [\"scientific_name\"], as_index=False, dropna=False\n",
    ").apply(\n",
    "    lambda x: pd.Series(\n",
    "        {\n",
    "            \"observed_ecoregions\": list(\n",
    "                [item for sublist in x[\"observed_ecoregions\"] for item in sublist]\n",
    "            ),\n",
    "            \"rights\": list([item for sublist in x[\"rights\"] for item in sublist]),\n",
    "            \"native_ecoregions\": list(\n",
    "                set(\n",
    "                    [\n",
    "                        item\n",
    "                        for sublist in x[\"native_ecoregions\"]\n",
    "                        for item in sublist\n",
    "                        if item is not None\n",
    "                    ]\n",
    "                )\n",
    "            ),\n",
    "            \"freshwater_ecoregions\": list(\n",
    "                set(\n",
    "                    [\n",
    "                        item\n",
    "                        for sublist in x[\"freshwater_ecoregions\"]\n",
    "                        for item in sublist\n",
    "                        if item is not None\n",
    "                    ]\n",
    "                )\n",
    "            ),\n",
    "            \"common_name\": list(x[\"common_name\"].unique()),\n",
    "            \"species_type\": list(x[\"species_type\"].unique()),\n",
    "            \"scientific_name\": list(x[\"scientific_name\"].unique()),\n",
    "            \"kingdom\": list(x[\"kingdom\"].unique()),\n",
    "            \"phylum\": list(x[\"phylum\"].unique()),\n",
    "            \"class\": list(x[\"class\"].unique()),\n",
    "            \"order\": list(x[\"order\"].unique()),\n",
    "            \"family\": list(x[\"family\"].unique()),\n",
    "            \"genus\": list(x[\"genus\"].unique()),\n",
    "        }\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "partial_duplicates_grouped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean = partial_duplicates_grouped\n",
    "\n",
    "df_clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find rows of df_clean where length of scientific_name is greater than 1\n",
    "scientific_dups = df_clean[df_clean[\"scientific_name\"].str.len() > 1]\n",
    "\n",
    "scientific_dups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kingdom_dups = df_clean[df_clean[\"kingdom\"].str.len() > 1]\n",
    "\n",
    "kingdom_dups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "phylum_dups = df_clean[df_clean[\"phylum\"].str.len() > 1]\n",
    "\n",
    "phylum_dups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_dups = df_clean[df_clean[\"class\"].str.len() > 1]\n",
    "\n",
    "class_dups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "order_dups = df_clean[df_clean[\"order\"].str.len() > 1]\n",
    "\n",
    "order_dups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "family_dups = df_clean[df_clean[\"family\"].str.len() > 1]\n",
    "\n",
    "family_dups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "genus_dups = df_clean[df_clean[\"genus\"].str.len() > 1]\n",
    "\n",
    "genus_dups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "species_type_dups = df_clean[df_clean[\"species_type\"].str.len() > 1]\n",
    "\n",
    "species_type_dups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(df_clean)):\n",
    "    print(i)\n",
    "    df_clean.loc[i, \"kingdom\"] = df_clean.loc[i, \"kingdom\"][0]\n",
    "    df_clean.loc[i, \"phylum\"] = df_clean.loc[i, \"phylum\"][0]\n",
    "    df_clean.loc[i, \"class\"] = df_clean.loc[i, \"class\"][0]\n",
    "    df_clean.loc[i, \"order\"] = df_clean.loc[i, \"order\"][0]\n",
    "    df_clean.loc[i, \"family\"] = df_clean.loc[i, \"family\"][0]\n",
    "    df_clean.loc[i, \"genus\"] = df_clean.loc[i, \"genus\"][0]\n",
    "    df_clean.loc[i, \"species_type\"] = df_clean.loc[i, \"species_type\"][0]\n",
    "\n",
    "\n",
    "df_clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "common_name_dups = df_clean[df_clean[\"common_name\"].str.len() > 1]\n",
    "\n",
    "common_name_dups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean[\"common_name\"] = df_clean[\"common_name\"].apply(\n",
    "    lambda x: [i for i in x if i is not None]\n",
    ")\n",
    "\n",
    "df_clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(df_clean)):\n",
    "    print(i)\n",
    "    if len(df_clean.loc[i, \"common_name\"]) == 0:\n",
    "        df_clean.loc[i, \"common_name\"] = None\n",
    "    else:\n",
    "        df_clean.loc[i, \"common_name\"] = df_clean.loc[i, \"common_name\"][0]\n",
    "\n",
    "df_clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(df_clean)):\n",
    "    print(i)\n",
    "\n",
    "    df_clean.loc[i, \"scientific_name\"] = df_clean.loc[i, \"scientific_name\"][0]\n",
    "\n",
    "\n",
    "df_clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove rows in df where scientific_name is in duplicates\n",
    "df = df[~df[\"scientific_name\"].isin(duplicates[\"scientific_name\"])]\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged = pd.concat([df, df_clean], axis=0)\n",
    "\n",
    "merged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_duplicates = merged[merged.duplicated(subset=[\"scientific_name\"], keep=False)]\n",
    "\n",
    "merged_duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find rows where scientific_name does not equal 2 words\n",
    "scientific = df[df[\"scientific_name\"].str.count(\" \") != 1]\n",
    "\n",
    "scientific"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove rows where scientific_name does not equal 2 words\n",
    "df = df[df[\"scientific_name\"].str.count(\" \") == 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find rows where kingdom does not equal 1 word\n",
    "kingdom = df[df[\"kingdom\"].str.count(\" \") > 0]\n",
    "\n",
    "kingdom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# replace kingdom value incertae sedis with kingdom value Bacteria\n",
    "df[\"kingdom\"].replace(to_replace=\"incertae sedis\", value=\"Bacteria\", inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find rows where kingdom does not equal 1 word\n",
    "phylum = df[df[\"phylum\"].str.count(\" \") != 0]\n",
    "\n",
    "phylum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find rows where kingdom does not equal 1 word\n",
    "class_1 = df[df[\"class\"].str.count(\" \") != 0]\n",
    "\n",
    "class_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove rows where class does not equal 1 word skipping None values\n",
    "class_remove = class_1[class_1[\"class\"].notnull()]\n",
    "\n",
    "class_remove"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove values in class_remove from df\n",
    "df = df[~df.index.isin(class_remove.index)]\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find rows where kingdom does not equal 1 word\n",
    "order = df[df[\"order\"].str.count(\" \") != 0]\n",
    "\n",
    "order"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "order_remove = order[order[\"order\"].notnull()]\n",
    "\n",
    "order_remove"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[~df.index.isin(order_remove.index)]\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find rows where kingdom does not equal 1 word\n",
    "family = df[df[\"family\"].str.count(\" \") != 0]\n",
    "\n",
    "family"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "family_remove = family[family[\"family\"].notnull()]\n",
    "\n",
    "family_remove"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[~df.index.isin(family_remove.index)]\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find rows where kingdom does not equal 1 word\n",
    "genus = df[df[\"genus\"].str.count(\" \") > 0]\n",
    "\n",
    "genus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find rows in scientific_name that contain special characters excluding -\n",
    "special_scientific_name = df[df[\"scientific_name\"].str.contains(\"[^a-zA-Z0-9- ]\")]\n",
    "\n",
    "special_scientific_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[~df.index.isin(special_scientific_name.index)]\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find rows in scientific_name that contain special characters excluding - skipping None values\n",
    "special_kingdom = df[\n",
    "    df[\"kingdom\"].str.contains(\"[^a-zA-Z0-9- ]\") & df[\"kingdom\"].notnull()\n",
    "]\n",
    "\n",
    "special_kingdom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find rows in scientific_name that contain special characters excluding - skipping None values\n",
    "special_phylum = df[\n",
    "    df[\"phylum\"].str.contains(\"[^a-zA-Z0-9- ]\") & df[\"phylum\"].notnull()\n",
    "]\n",
    "\n",
    "special_phylum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find rows in scientific_name that contain special characters excluding - skipping None values\n",
    "special_class = df[df[\"class\"].str.contains(\"[^a-zA-Z0-9- ]\") & df[\"class\"].notnull()]\n",
    "\n",
    "special_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find rows in scientific_name that contain special characters excluding - skipping None values\n",
    "special_order = df[df[\"order\"].str.contains(\"[^a-zA-Z0-9- ]\") & df[\"order\"].notnull()]\n",
    "\n",
    "special_order"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find rows in scientific_name that contain special characters excluding - skipping None values\n",
    "special_family = df[\n",
    "    df[\"family\"].str.contains(\"[^a-zA-Z0-9- ]\") & df[\"family\"].notnull()\n",
    "]\n",
    "\n",
    "special_family"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find rows in scientific_name that contain special characters excluding - skipping None values\n",
    "special_genus = df[df[\"genus\"].str.contains(\"[^a-zA-Z0-9- ]\") & df[\"genus\"].notnull()]\n",
    "\n",
    "special_genus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find rows in common_name that contain special characters excluding - and ' skipping None values\n",
    "special_common_name = df[\n",
    "    df[\"common_name\"].str.contains(\"[^a-zA-Z0-9-' ]\") & df[\"common_name\"].notnull()\n",
    "]\n",
    "\n",
    "special_common_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove common_name in rows with following index: 326623, 296419, 280009, 247333, 197160, 166917, 154546, 82219, 48067\n",
    "\n",
    "\n",
    "for i in [247526]:\n",
    "    # for i in [326623, 296419, 280009, 247333, 197160, 166917, 154546, 82219, 48067]:\n",
    "    df.loc[i, \"common_name\"] = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.loc[241715, \"common_name\"] = \"Flatclaw hermit crab\"\n",
    "# df.loc[241704, \"common_name\"] = \"Longclaw hermit crab\"\n",
    "# df.loc[214538, \"common_name\"] = \"Maraj Short-tailed Opossum\"\n",
    "# df.loc[197592, \"common_name\"] = \"Gilded Royal River Cruiser\"\n",
    "# df.loc[197017, \"common_name\"] = \"Tenta macoma\"\n",
    "# df.loc[196242, \"common_name\"] = \"Lewis' yellow-loosestrife\"\n",
    "# df.loc[157228, \"common_name\"] = \"African False Tiger\"\n",
    "# df.loc[133023, \"common_name\"] = \"northern moon snail\"\n",
    "# df.loc[122097, \"common_name\"] = \"Wemmershoek Marsh Heath\"\n",
    "# df.loc[116324, \"common_name\"] = \"Sand flea\"\n",
    "# df.loc[36620, \"common_name\"] = \"Diamond Pittosporum\"\n",
    "df.loc[19301, \"common_name\"] = \"longtail tuna\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find unique values in species_type\n",
    "df[\"species_type\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find rows where length of observed_ecoregions is 0\n",
    "df[df[\"observed_ecoregions\"].str.len() == 0]\n",
    "\n",
    "# remove rows where length of observed_ecoregions is 0\n",
    "df = df[df[\"observed_ecoregions\"].str.len() != 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find unique values in list observed_ecoregions\n",
    "unique_observed = []\n",
    "\n",
    "for i in df[\"observed_ecoregions\"]:\n",
    "    # print(i)\n",
    "\n",
    "    for j in i:\n",
    "        unique_observed.append(j)\n",
    "\n",
    "unique_observed = list(set(unique_observed))\n",
    "\n",
    "unique_observed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove values in observed_ecoregions that equal <NA>\n",
    "df[\"observed_ecoregions\"] = df[\"observed_ecoregions\"].apply(\n",
    "    lambda x: x[x != \"<NA>\"] if (\"<NA>\" in x) else x\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reset index of df\n",
    "df = df.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_parquet(\n",
    "    \"/media/muskrat/T7 Shield/eco_data/v4/occurences/step_4/processing/step_3/final_temp.parquet\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find unique values in list observed_ecoregions\n",
    "unique_native = []\n",
    "\n",
    "for i in df[\"native_ecoregions\"]:\n",
    "    # print(i)\n",
    "\n",
    "    for j in i:\n",
    "        unique_native.append(j)\n",
    "\n",
    "unique_native = list(set(unique_native))\n",
    "\n",
    "unique_native"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fill missing values of native_ecoregions and freshwater_ecoregions with empty list\n",
    "for i in range(len(df)):\n",
    "    print(i)\n",
    "    #    print(type(df_clean.loc[i, \"native_ecoregions\"]))\n",
    "    if df.loc[i, \"native_ecoregions\"] is None:\n",
    "        df.loc[i, \"native_ecoregions\"] = [None]\n",
    "    if df.loc[i, \"freshwater_ecoregions\"] is None:\n",
    "        df.loc[i, \"freshwater_ecoregions\"] = [None]\n",
    "\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check if each row in native_ecoregions is a list\n",
    "type_list = []\n",
    "list_count = 0\n",
    "array_count = 0\n",
    "for i in df[\"freshwater_ecoregions\"]:\n",
    "    if type(i) not in type_list:\n",
    "        type_list.append(type(i))\n",
    "        # count number of times each type appears in type_list\n",
    "    if type(i) == list:\n",
    "        list_count += 1\n",
    "    else:\n",
    "        array_count += 1\n",
    "\n",
    "print(type_list)\n",
    "\n",
    "print(list_count)\n",
    "print(array_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert native_ecoregions values that are of type list to numpy array\n",
    "df[\"native_ecoregions\"] = df[\"native_ecoregions\"].apply(\n",
    "    lambda x: np.array(x) if type(x) == list else x\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"native_ecoregions\"] = df[\"native_ecoregions\"].apply(\n",
    "    lambda x: x[x != \"<NA>\"] if (\"<NA>\" in x) else x\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"native_ecoregions\"] = df[\"native_ecoregions\"].apply(\n",
    "    lambda x: x[x != \"[]\"] if (\"[]\" in x) else x\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_freshwater = []\n",
    "\n",
    "for i in df[\"freshwater_ecoregions\"]:\n",
    "    print(i)\n",
    "\n",
    "    for j in i:\n",
    "        unique_freshwater.append(j)\n",
    "\n",
    "unique_freshwater = list(set(unique_freshwater))\n",
    "\n",
    "unique_freshwater"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"freshwater_ecoregions\"] = df[\"freshwater_ecoregions\"].apply(\n",
    "    lambda x: np.array(x) if type(x) == list else x\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove None values from native_ecoregions and freshwater_ecoregions\n",
    "df[\"native_ecoregions\"] = df[\"native_ecoregions\"].apply(\n",
    "    lambda x: [i for i in x if i is not None]\n",
    ")\n",
    "\n",
    "df[\"freshwater_ecoregions\"] = df[\"freshwater_ecoregions\"].apply(\n",
    "    lambda x: [i for i in x if i is not None]\n",
    ")\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print max length of native_ecoregions and freshwater_ecoregions\n",
    "print(df[\"native_ecoregions\"].str.len().max())\n",
    "print(df[\"freshwater_ecoregions\"].str.len().max())\n",
    "print(df[\"observed_ecoregions\"].str.len().max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove duplicates from observed_ecoregions, native_ecoregions, and freshwater_ecoregions\n",
    "df[\"observed_ecoregions\"] = df[\"observed_ecoregions\"].apply(\n",
    "    lambda x: [i for n, i in enumerate(x) if i not in x[n + 1 :]]\n",
    ")\n",
    "\n",
    "df[\"native_ecoregions\"] = df[\"native_ecoregions\"].apply(\n",
    "    lambda x: [i for n, i in enumerate(x) if i not in x[n + 1 :]]\n",
    ")\n",
    "\n",
    "df[\"freshwater_ecoregions\"] = df[\"freshwater_ecoregions\"].apply(\n",
    "    lambda x: [i for n, i in enumerate(x) if i not in x[n + 1 :]]\n",
    ")\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert native_ecoregions values that equal an empty list to None\n",
    "df.loc[df[\"native_ecoregions\"].str.len() == 0, \"native_ecoregions\"] = None\n",
    "\n",
    "# convert freshwater_ecoregions values that equal an empty list to None\n",
    "df.loc[df[\"freshwater_ecoregions\"].str.len() == 0, \"freshwater_ecoregions\"] = None\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(df)):\n",
    "    print(i)\n",
    "\n",
    "    if df.loc[i, \"rights\"] is None:\n",
    "        df.loc[i, \"rights\"] = [None]\n",
    "\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"rights\"] = df[\"rights\"].apply(lambda x: [i for i in x if i is not None])\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[df[\"rights\"].str.len() == 0, \"rights\"] = None\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print max length of rights column\n",
    "print(df[\"rights\"].str.len().max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list unique values in species_type column\n",
    "df[\"species_type\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check for missing values in species_type column\n",
    "df[\"species_type\"].isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check for missing values in species_type column\n",
    "df[\"scientific_name\"].isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check for rows where length of observed_ecoregions is 0\n",
    "df[df[\"observed_ecoregions\"].str.len() == 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check for duplicates in scientific_name column\n",
    "df[df.duplicated(subset=[\"scientific_name\"], keep=False)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[\n",
    "    [\n",
    "        \"kingdom\",\n",
    "        \"phylum\",\n",
    "        \"class\",\n",
    "        \"order\",\n",
    "        \"family\",\n",
    "        \"genus\",\n",
    "        \"scientific_name\",\n",
    "        \"observed_ecoregions\",\n",
    "        \"native_ecoregions\",\n",
    "        \"freshwater_ecoregions\",\n",
    "        \"common_name\",\n",
    "        \"species_type\",\n",
    "        \"rights\",\n",
    "    ]\n",
    "]\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_path = input(\"Enter the file path: \")\n",
    "\n",
    "df.to_parquet(final_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_json(\n",
    "    \"/media/muskrat/T7 Shield/eco_data/v4/occurences/final/final_retry.json\",\n",
    "    orient=\"records\",\n",
    "    force_ascii=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[\n",
    "    [\n",
    "        \"kingdom\",\n",
    "        \"phylum\",\n",
    "        \"class\",\n",
    "        \"order\",\n",
    "        \"family\",\n",
    "        \"genus\",\n",
    "        \"scientific_name\",\n",
    "        \"observed_ecoregions\",\n",
    "        \"native_ecoregions\",\n",
    "        \"freshwater_ecoregions\",\n",
    "        \"common_name\",\n",
    "        \"species_type\",\n",
    "    ]\n",
    "]\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_json(\n",
    "    \"/media/muskrat/T7 Shield/eco_data/v4/occurences/final/final_retry_no_rights.json\",\n",
    "    orient=\"records\",\n",
    "    force_ascii=False,\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "eco",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
