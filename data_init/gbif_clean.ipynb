{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import vaex\n",
    "\n",
    "pd.set_option(\"display.max_columns\", None)\n",
    "# pd.set_option('display.max_rows', 100)\n",
    "# pd.set_option('display.max_seq_items', 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_essential_path = input(\"Enter the file path: \")\n",
    "\n",
    "df_essential = vaex.open(df_essential_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_essential\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# count the number of na values in column species\n",
    "species_na = df_essential[\"species\"].isna().sum()\n",
    "\n",
    "latitude_na = df_essential[\"decimalLatitude\"].isna().sum()\n",
    "\n",
    "longitude_na = df_essential[\"decimalLongitude\"].isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove rows in df_essential where species is NA\n",
    "df_essential = df_essential.dropna(\n",
    "    column_names=[\"species\", \"decimalLatitude\", \"decimalLongitude\"]\n",
    ")\n",
    "\n",
    "df_essential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# recount the number of na values in column species\n",
    "species_na = df_essential[\"species\"].isna().sum()\n",
    "\n",
    "latitude_na = df_essential[\"decimalLatitude\"].isna().sum()\n",
    "\n",
    "longitude_na = df_essential[\"decimalLongitude\"].isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find unique species names in df_essential\n",
    "species_unique = df_essential[\"species\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert df_essential to pandas dataframe from vaex dataframe\n",
    "# df_essential = df_essential.to_pandas_df()\n",
    "\n",
    "# df_essential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check if the species column contains any names that are longer than 2 words\n",
    "# currently only keeping 2 word names and removing sub species\n",
    "\n",
    "\n",
    "# change first value in species column of df_essential to 'a b c'\n",
    "# df_essential[\"species\"][0] = \"a b c\"\n",
    "# df_essential[\"species\"][3] = \"d e f\"\n",
    "\n",
    "# df_essential\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find number of words in the species column of df_essential\n",
    "# species_words = df_essential[\"species\"].to_numpy()\n",
    "\n",
    "# # find number of words in each string in ndarray species_words\n",
    "# species_value = df_essential[\"species\"].str.split().str.len()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# species_values = np.array([len(word.split()) for word in species_words])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make a new column in df_essential that displays species_values\n",
    "# df_essential[\"species_values\"] = species_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if an item at index i in species_values is greater than 2, remove it from df_essential at the same index\n",
    "# for i in range(len(species_values)):\n",
    "#     if species_values[i] > 2:\n",
    "#         df_essential = df_essential.drop(i)\n",
    "\n",
    "\n",
    "# # find items in species_value whose length is greater than 2\n",
    "# species_values = species_value[species_value > 2]\n",
    "# # convert species_value from expression to numpy array\n",
    "# species_value = np.array([len(word.split()) for word in species_words])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_essential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read cleaned df_essential into a parquet file where user can input the file path\n",
    "df_clean_path = input(\"Enter the file path: \")\n",
    "df_essential.export_parquet(df_clean_path)\n",
    "\n",
    "# write df_essential to parquet file using pandas to_parquet\n",
    "# df_essential.to_parquet(df_clean_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "eco",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
