{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import glob\n",
    "import os\n",
    "import geopandas as gpd\n",
    "\n",
    "pd.set_option('display.max_columns', None)\n",
    "# pd.set_option('display.max_rows', None)\n",
    "# pd.set_option('display.max_columns', None)\n",
    "# pd.set_option('display.width', None)\n",
    "# pd.set_option('display.max_colwidth', None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " \n",
    "# WWF ECOREGION AND USA COUNTY MAP DATA\n",
    "\n",
    "# read in ecoregion map data and US county data\n",
    "counties = gpd.read_file(\n",
    "    '/home/muskrat/Documents/eco_data_copy/wwf_map_data/us_counties.geojson')\n",
    "ecomap = gpd.read_file(\n",
    "    '/home/muskrat/Documents/eco_data_copy/wwf_map_data/map.geojson')\n",
    "\n",
    "# ecotest = ecomap.loc[ecomap['unique_id'] == 420].reset_index(drop=True)\n",
    "# county_inner = counties.loc[0]\n",
    "# county_outer = counties.loc[1]\n",
    "# county_split = counties.loc[(counties['NAME'] == 'Brown') & (counties['STATE_NAME'] == 'Ohio')]\n",
    "\n",
    "\n",
    "eco_county = []\n",
    "# eco_id = {'unique_id': str(ecotest['unique_id'].values[0])}\n",
    "# eco_county.append(eco_id)\n",
    "# selected_counties = []\n",
    "\n",
    "# check whether a each county is inside or intersects an ecoregion or if ecoregion is inside a county\n",
    "for i in range(len(ecomap)):\n",
    "    # get unique id of each ecoregion\n",
    "    eco_id = {'unique_id': str(ecomap.loc[i, 'unique_id'])}\n",
    "\n",
    "    selected_counties = []\n",
    "\n",
    "    for j in range(len(counties)):\n",
    "        # check whether county is within ecoregion\n",
    "        # contains = ecomap.loc[i, 'geometry'].contains(counties.loc[j, 'geometry'])\n",
    "        # intersects = ecomap.loc[i, 'geometry'].intersects(counties.loc[j, 'geometry'])\n",
    "        within = ecomap.loc[i, 'geometry'].within(counties.loc[j, 'geometry'])\n",
    "\n",
    "        # print(counties.loc[i, 'NAME'])\n",
    "        # if county is in ecoregion push to selected counties list\n",
    "        # if contains == True:\n",
    "        if within == True:\n",
    "            # if contains == True or intersects == True:\n",
    "            selected_counties.append({\n",
    "                'county': counties.loc[j, 'NAME'],\n",
    "                'state': counties.loc[j, 'STATE_NAME']})\n",
    "            # eco_id['eco_counties'] = selected_counties\n",
    "       # add selected counties to eco_id dict\n",
    "    eco_id['eco_counties'] = selected_counties\n",
    "    # push counties to eco_county list\n",
    "    eco_county.append(eco_id)\n",
    "\n",
    "\n",
    "full_county = []\n",
    "\n",
    "# check if there are any counties in ecoregion for usa. if they are push to full county list\n",
    "for i in range(len(eco_county)):\n",
    "    if eco_county[i]['eco_counties']:\n",
    "        full_county.append(eco_county[i])\n",
    "\n",
    "na_county = []\n",
    "\n",
    "# check if ecoregion has unique_id. if it does push to na_county\n",
    "for i in range(len(full_county)):\n",
    "    if full_county[i]['unique_id'] != 'nan':\n",
    "        na_county.append(full_county[i])\n",
    "\n",
    "county_data = pd.DataFrame(na_county)\n",
    "eco_county_data = pd.json_normalize(na_county,\n",
    "                                   record_path='eco_counties',\n",
    "                                   meta=['unique_id'])\n",
    "\n",
    "# Extract relevant columns\n",
    "county_data = eco_county_data[['unique_id', 'county']]\n",
    "state_data = eco_county_data[['unique_id', 'state']]\n",
    "\n",
    "# Group by unique_id\n",
    "county_group = county_data.groupby('unique_id')['county'].apply(list).reset_index()\n",
    "state_group = state_data.groupby('unique_id')['state'].apply(list).reset_index()\n",
    "\n",
    "# Merge grouped data\n",
    "final_eco_county = pd.merge(county_group, state_group, on='unique_id', how='left')\n",
    "\n",
    "# Convert to JSON\n",
    "eco_county_json = final_eco_county.to_json(orient='records', force_ascii=False)\n",
    "\n",
    "\n",
    "\n",
    "file = open(\"eco_county_prep.json\", \"w\")\n",
    "file.write(eco_county_json)\n",
    "file.close\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# USA ECO COUNTIES\n",
    "\n",
    "eco_county = pd.read_json('/home/muskrat/Desktop/eco_county_prep.json')\n",
    "\n",
    "# convert to dataframe and group county and state into dict.\n",
    "county = ['county', 'state']\n",
    "eco_county['eco_counties'] = eco_county[county].to_dict(orient='records')\n",
    "\n",
    "# group by unique id\n",
    "eco_group = eco_county.groupby(\n",
    "    'unique_id')['eco_counties'].apply(list).reset_index()\n",
    "# eco_group = eco_county.groupby('unique_id')['eco_counties']\n",
    "\n",
    "# convert to list\n",
    "eco_counties = eco_group['eco_counties'].to_list()\n",
    "\n",
    "eco_counties_test = eco_counties\n",
    "\n",
    "# remove duplicates from list of counties and states\n",
    "for j in range(len(eco_counties_test)):\n",
    "\n",
    "    eco_counties_test[j] = [i for n, i in enumerate(\n",
    "        eco_counties_test[j]) if i not in eco_counties_test[j][n + 1:]]\n",
    "\n",
    "\n",
    "eco_counties_df = pd.Series(eco_counties_test, name='counties_final')\n",
    "\n",
    "group_final = eco_group.merge(eco_counties_df, left_index=True, right_index=True).reindex(\n",
    "    columns=['unique_id', 'counties_final'])\n",
    "\n",
    "group_final_json = group_final.to_json(orient='records', force_ascii=False)\n",
    "repr(group_final_json)\n",
    "\n",
    "file = open(\"eco_county_within.json\", \"w\")\n",
    "file.write(group_final_json)\n",
    "file.close\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    " \n",
    "# USA ECO COUNTIES\n",
    "\n",
    "# eco_county_contains = pd.read_json(\n",
    "#     '/home/muskrat/Documents/eco_data_copy/main_eco_data/eco_county_contains.json')\n",
    "# eco_county_intersects = pd.read_json(\n",
    "#     '/home/muskrat/Documents/eco_data_copy/main_eco_data/eco_county_intersects.json')\n",
    "# eco_county_within = pd.read_json(\n",
    "#     '/home/muskrat/Documents/eco_data_copy/main_eco_data/eco_county_within.json')\n",
    "\n",
    "\n",
    " \n",
    "# USA ECO COUNTIES\n",
    "\n",
    "eco_ods = pd.read_excel('/home/muskrat/Documents/eco_data_copy/US_county_plants/397/397.ods',\n",
    "                        index_col=0, sheet_name=None, engine=('odf'))\n",
    "\n",
    "# put all sheets in one dataframe\n",
    "eco_df = pd.concat([v for k, v in eco_ods.items()])\n",
    "eco_df.reset_index(inplace=True)\n",
    "\n",
    "# add unique id column with ecoregion value\n",
    "eco_df['unique_id'] = '397'\n",
    "\n",
    " \n",
    "# USA ECO COUNTIES\n",
    "# remove duplicate species\n",
    "eco_df.drop_duplicates(['Scientific Name'], inplace=True, ignore_index=True)\n",
    "\n",
    " \n",
    "# USA ECO COUNTIES\n",
    "\n",
    "eco_subset = eco_df[['Plant Type', 'Scientific Name', 'Common Name',\n",
    "                'Plant Family', 'Native Status', 'unique_id']]\n",
    "\n",
    "eco_json = eco_subset.to_json(orient='records', force_ascii=False)\n",
    "repr(eco_json)\n",
    "\n",
    "file = open(\"eco_county_397.json\", \"w\")\n",
    "file.write(eco_json)\n",
    "file.close\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# j_test = pd.read_json('/home/muskrat/Documents/eco_data_copy/US_county_plants/397/eco_county_397.json')\n",
    "\n",
    " \n",
    "# USA ECO COUNTIES\n",
    "\n",
    "# read in all json files and merge into one dataframe\n",
    "json_dir = '/home/muskrat/Documents/eco_data_copy/US_county_plants/eco_json'\n",
    "\n",
    "json_pattern = os.path.join(json_dir, '*.json')\n",
    "file_list = glob.glob(json_pattern)\n",
    "\n",
    "dfs = []\n",
    "for file in file_list:\n",
    "    with open(file) as f:\n",
    "        json_data = pd.json_normalize(json.loads(f.read()))\n",
    "        json_data['site'] = file.rsplit(\"/\", 1)[-1]\n",
    "    dfs.append(json_data)\n",
    "counties_init = pd.concat(dfs)\n",
    "counties_init.reset_index(drop=True, inplace=True)\n",
    "counties_init.drop('site', 1, inplace=True)\n",
    "\n",
    " \n",
    "\n",
    "counties_init['Plant Type'].replace(\n",
    "    to_replace='Tree, Shrub', value='Tree', inplace=True)\n",
    "counties_init['Plant Type'].replace(\n",
    "    to_replace='Herb (annual)', value='Wildflower', inplace=True)\n",
    "counties_init['Plant Type'].replace(\n",
    "    to_replace='Herb (perennial)', value='Wildflower', inplace=True)\n",
    "counties_init['Plant Type'].replace(\n",
    "    to_replace='Shrub, Herb (perennial)', value='Wildflower', inplace=True)\n",
    "counties_init['Plant Type'].replace(\n",
    "    to_replace='Graminoid (perennial)', value='Graminoid', inplace=True)\n",
    "counties_init['Plant Type'].replace(\n",
    "    to_replace='Graminoid (annual)', value='Graminoid', inplace=True)\n",
    "counties_init['Plant Type'].replace(\n",
    "    to_replace='Herb (annual or perennial)', value='Wildflower', inplace=True)\n",
    "counties_init['Plant Type'].replace(\n",
    "    to_replace='Herb (biennial or perennial)', value='Wildflower', inplace=True)\n",
    "counties_init['Plant Type'].replace(\n",
    "    to_replace='Herb (biennial)', value='Wildflower', inplace=True)\n",
    "counties_init['Plant Type'].replace(\n",
    "    to_replace='Herb (annual or biennial)', value='Wildflower', inplace=True)\n",
    "counties_init['Plant Type'].replace(\n",
    "    to_replace='Shrub, Herb (annual or perennial)', value='Wildflower', inplace=True)\n",
    "counties_init['Plant Type'].replace(\n",
    "    to_replace='Graminoid (annual or perennial)', value='Graminoid', inplace=True)\n",
    "counties_init['Plant Type'].replace(\n",
    "    to_replace='Shrub, Herb (biennial or perennial)', value='Wildflower', inplace=True)\n",
    "counties_init['Plant Type'].replace(\n",
    "    to_replace='Shrub, Herb (annual)', value='Wildflower', inplace=True)\n",
    "counties_init['Plant Type'].replace(\n",
    "    to_replace='Shrub (annual or perennial)', value='Shrub', inplace=True)\n",
    "counties_init['Plant Type'].replace(\n",
    "    to_replace='Herb', value='Wildflower', inplace=True)\n",
    "counties_init['Plant Type'].replace(\n",
    "    to_replace='Vine, Herb (annual or perennial)', value='Vine', inplace=True)\n",
    "counties_init['Plant Type'].replace(\n",
    "    to_replace='Vine, Herb (perennial)', value='Vine', inplace=True)\n",
    "counties_init['Plant Type'].replace(\n",
    "    to_replace='Shrub, Graminoid (perennial)', value='Graminoid', inplace=True)\n",
    "counties_init['Plant Type'].replace(\n",
    "    to_replace='Shrub, Herb (annual or perennial)', value='Wildflower', inplace=True)\n",
    "counties_init['Plant Type'].replace(\n",
    "    to_replace='Vine, Herb (annual)', value='Vine', inplace=True)\n",
    "counties_init['Plant Type'].replace(\n",
    "    to_replace='Vine, Shrub', value='Vine', inplace=True)\n",
    "counties_init['Plant Type'].replace(\n",
    "    to_replace='Vine, Shrub, Herb (perennial)', value='Vine', inplace=True)\n",
    "counties_init['Plant Type'].replace(\n",
    "    to_replace='Shrub, Herb (biennial or perennial)', value='Wildflower', inplace=True)\n",
    "counties_init['Plant Type'].replace(\n",
    "    to_replace='Tree, Vine, Shrub', value='Shrub', inplace=True)\n",
    "counties_init['Plant Type'].replace(\n",
    "    to_replace='Tree, Shrub, Herb (perennial)', value='Wildflower', inplace=True)\n",
    "counties_init['Plant Type'].replace(\n",
    "    to_replace='Vine, Shrub, Graminoid (perennial)', value='Graminoid', inplace=True)\n",
    "\n",
    "counties_init.loc[77973, 'Plant Type'] = 'Tree'\n",
    "counties_init.loc[93777, 'Plant Type'] = 'Tree'\n",
    "\n",
    " \n",
    "counties_unique = counties_init.drop_duplicates(['Scientific Name'])\n",
    "counties_unique.drop('unique_id', 1, inplace=True)\n",
    "counties_group = counties_init.groupby('Scientific Name')[\n",
    "    'unique_id'].apply(list).reset_index()\n",
    "\n",
    "counties_final = pd.merge(counties_unique, counties_group,\n",
    "                          on='Scientific Name', how='left')\n",
    "common_miss = counties_final.loc[pd.isna(counties_final[\"Common Name\"]), :]\n",
    "\n",
    " \n",
    "\n",
    "final_json = counties_final.to_json(orient='records', force_ascii=False)\n",
    "repr(final_json)\n",
    "\n",
    "final_miss = common_miss.to_json(orient='records', force_ascii=False)\n",
    "repr(final_miss)\n",
    "\n",
    "file = open(\"eco_county_prep.json\", \"w\")\n",
    "file.write(final_json)\n",
    "file.close\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# USA ECO COUNTIES\n",
    "\n",
    "eco_county = pd.read_json('/home/muskrat/Desktop/eco_county_prep.json')\n",
    "\n",
    "# convert to dataframe and group county and state into dict.\n",
    "county = ['county', 'state']\n",
    "eco_county['eco_counties'] = eco_county[county].to_dict(orient='records')\n",
    "\n",
    "# group by unique id\n",
    "eco_group = eco_county.groupby(\n",
    "    'unique_id')['eco_counties'].apply(list).reset_index()\n",
    "# eco_group = eco_county.groupby('unique_id')['eco_counties']\n",
    "\n",
    "# convert to list\n",
    "eco_counties = eco_group['eco_counties'].to_list()\n",
    "\n",
    "eco_counties_test = eco_counties\n",
    "\n",
    "# remove duplicates from list of counties and states\n",
    "for j in range(len(eco_counties_test)):\n",
    "\n",
    "    eco_counties_test[j] = [i for n, i in enumerate(\n",
    "        eco_counties_test[j]) if i not in eco_counties_test[j][n + 1:]]\n",
    "\n",
    "\n",
    "eco_counties_df = pd.Series(eco_counties_test, name='counties_final')\n",
    "\n",
    "group_final = eco_group.merge(eco_counties_df, left_index=True, right_index=True).reindex(\n",
    "    columns=['unique_id', 'counties_final'])\n",
    "\n",
    "group_final_json = group_final.to_json(orient='records', force_ascii=False)\n",
    "repr(group_final_json)\n",
    "\n",
    "file = open(\"eco_county_within.json\", \"w\")\n",
    "file.write(group_final_json)\n",
    "file.close\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "eco",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
