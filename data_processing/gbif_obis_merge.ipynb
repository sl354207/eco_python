{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "pd.set_option(\"display.max_columns\", None)\n",
    "# pd.set_option('display.max_rows', 100)\n",
    "# pd.set_option('display.max_seq_items', 100)\n",
    "\n",
    "# 400 meter coordinate accuracy\n",
    "# 1923 earliest year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in samples_spatial\n",
    "samples_path = input(\"Enter the file path: \")\n",
    "\n",
    "samples = pd.read_parquet(samples_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in obis_spatial\n",
    "obis_path = input(\"Enter the file path: \")\n",
    "\n",
    "obis = pd.read_parquet(obis_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "obis\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inner = pd.merge(samples, obis, how=\"inner\", on=[\n",
    "                 \"scientific_name\"], indicator=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inner[\"combined_id\"] = inner[\"unique_id_x\"].apply(lambda x: x.tolist()) + inner[\n",
    "    \"unique_id_y\"\n",
    "].apply(lambda x: x.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inner[\"combined_id\"] = inner[\"combined_id\"].apply(set).apply(list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "check_combined_id = inner[[\"unique_id_x\", \"unique_id_y\", \"combined_id\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inner = inner.drop([\"unique_id_x\", \"unique_id_y\"], axis=1)\n",
    "\n",
    "inner.rename(columns={\"combined_id\": \"unique_id\"}, inplace=True)\n",
    "\n",
    "del check_combined_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inner[\"combined_rights\"] = inner[\"rights_x\"].apply(lambda x: x.tolist()) + inner[\n",
    "    \"rights_y\"\n",
    "].apply(lambda x: x.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check combined_rights\n",
    "print(\n",
    "    f\"right {inner['rights_x'][0]}, left {inner['rights_y'][0]}, combined {inner['combined_rights'][0]}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove duplicates\n",
    "rights = inner[\"combined_rights\"].to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for j in range(len(rights)):\n",
    "    print(j)\n",
    "    rights[j] = [i for n, i in enumerate(\n",
    "        rights[j]) if i not in rights[j][n + 1:]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rights = pd.Series(rights, name=\"rights\")\n",
    "\n",
    "inner[\"combined_rights\"] = rights\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# recheck combined_rights\n",
    "print(\n",
    "    f\"right {inner['rights_x'][493]}, left {inner['rights_y'][493]}, combined {inner['combined_rights'][493]}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inner = inner.drop([\"rights_x\", \"rights_y\"], axis=1)\n",
    "\n",
    "inner.rename(columns={\"combined_rights\": \"rights\"}, inplace=True)\n",
    "\n",
    "del rights, j"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inner\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# keep columns with less missing values\n",
    "\n",
    "kingdom_x_missing = inner[\"kingdom_x\"].isna().sum()\n",
    "\n",
    "kingdom_y_missing = inner[\"kingdom_y\"].isna().sum()\n",
    "\n",
    "# drop the kingdom column from inner that contains more missing values\n",
    "if kingdom_x_missing > kingdom_y_missing:\n",
    "    inner = inner.drop([\"kingdom_x\"], axis=1)\n",
    "    inner.rename(columns={\"kingdom_y\": \"kingdom\"}, inplace=True)\n",
    "else:\n",
    "    inner = inner.drop([\"kingdom_y\"], axis=1)\n",
    "    inner.rename(columns={\"kingdom_x\": \"kingdom\"}, inplace=True)\n",
    "\n",
    "phylum_x_missing = inner[\"phylum_x\"].isna().sum()\n",
    "\n",
    "phylum_y_missing = inner[\"phylum_y\"].isna().sum()\n",
    "\n",
    "# drop the phylum column from inner that contains more missing values\n",
    "\n",
    "if phylum_x_missing > phylum_y_missing:\n",
    "    inner = inner.drop([\"phylum_x\"], axis=1)\n",
    "    inner.rename(columns={\"phylum_y\": \"phylum\"}, inplace=True)\n",
    "else:\n",
    "    inner = inner.drop([\"phylum_y\"], axis=1)\n",
    "    inner.rename(columns={\"phylum_x\": \"phylum\"}, inplace=True)\n",
    "\n",
    "# find sum of missing values in inner['class_x']\n",
    "class_x_missing = inner[\"class_x\"].isna().sum()\n",
    "\n",
    "class_y_missing = inner[\"class_y\"].isna().sum()\n",
    "\n",
    "# drop the class column from inner that contains more missing values\n",
    "if class_x_missing > class_y_missing:\n",
    "    inner = inner.drop([\"class_x\"], axis=1)\n",
    "    inner.rename(columns={\"class_y\": \"class\"}, inplace=True)\n",
    "else:\n",
    "    inner = inner.drop([\"class_y\"], axis=1)\n",
    "    inner.rename(columns={\"class_x\": \"class\"}, inplace=True)\n",
    "\n",
    "# check\n",
    "class_missing = inner[\"class\"].isna().sum()\n",
    "\n",
    "order_x_missing = inner[\"order_x\"].isna().sum()\n",
    "\n",
    "order_y_missing = inner[\"order_y\"].isna().sum()\n",
    "\n",
    "# drop the order column from inner that contains more missing values\n",
    "\n",
    "if order_x_missing > order_y_missing:\n",
    "    inner = inner.drop([\"order_x\"], axis=1)\n",
    "    inner.rename(columns={\"order_y\": \"order\"}, inplace=True)\n",
    "else:\n",
    "    inner = inner.drop([\"order_y\"], axis=1)\n",
    "    inner.rename(columns={\"order_x\": \"order\"}, inplace=True)\n",
    "\n",
    "family_x_missing = inner[\"family_x\"].isna().sum()\n",
    "\n",
    "family_y_missing = inner[\"family_y\"].isna().sum()\n",
    "\n",
    "# drop the family column from inner that contains more missing values\n",
    "\n",
    "if family_x_missing > family_y_missing:\n",
    "    inner = inner.drop([\"family_x\"], axis=1)\n",
    "    inner.rename(columns={\"family_y\": \"family\"}, inplace=True)\n",
    "else:\n",
    "    inner = inner.drop([\"family_y\"], axis=1)\n",
    "    inner.rename(columns={\"family_x\": \"family\"}, inplace=True)\n",
    "\n",
    "\n",
    "genus_x_missing = inner[\"genus_x\"].isna().sum()\n",
    "\n",
    "genus_y_missing = inner[\"genus_y\"].isna().sum()\n",
    "\n",
    "# drop the genus column from inner that contains more missing values\n",
    "\n",
    "if genus_x_missing > genus_y_missing:\n",
    "    inner = inner.drop([\"genus_x\"], axis=1)\n",
    "    inner.rename(columns={\"genus_y\": \"genus\"}, inplace=True)\n",
    "else:\n",
    "    inner = inner.drop([\"genus_y\"], axis=1)\n",
    "    inner.rename(columns={\"genus_x\": \"genus\"}, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del (\n",
    "    genus_y_missing,\n",
    "    genus_x_missing,\n",
    "    family_y_missing,\n",
    "    family_x_missing,\n",
    "    order_y_missing,\n",
    "    order_x_missing,\n",
    "    class_y_missing,\n",
    "    class_x_missing,\n",
    "    phylum_y_missing,\n",
    "    phylum_x_missing,\n",
    "    kingdom_y_missing,\n",
    "    kingdom_x_missing,\n",
    "    class_missing,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop _merge column\n",
    "inner = inner.drop(\"_merge\", axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inner = inner[\n",
    "    [\n",
    "        \"kingdom\",\n",
    "        \"phylum\",\n",
    "        \"class\",\n",
    "        \"order\",\n",
    "        \"family\",\n",
    "        \"genus\",\n",
    "        \"scientific_name\",\n",
    "        \"unique_id\",\n",
    "        \"rights\",\n",
    "    ]\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inner\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outer = pd.merge(samples, obis, how=\"outer\", on=[\n",
    "                 \"scientific_name\"], indicator=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "left = outer.loc[\n",
    "    outer._merge == \"left_only\",\n",
    "    [\n",
    "        \"kingdom_x\",\n",
    "        \"phylum_x\",\n",
    "        \"class_x\",\n",
    "        \"order_x\",\n",
    "        \"family_x\",\n",
    "        \"genus_x\",\n",
    "        \"scientific_name\",\n",
    "        \"unique_id_x\",\n",
    "        \"rights_x\",\n",
    "    ],\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "left.rename(\n",
    "    columns={\n",
    "        \"kingdom_x\": \"kingdom\",\n",
    "        \"phylum_x\": \"phylum\",\n",
    "        \"class_x\": \"class\",\n",
    "        \"order_x\": \"order\",\n",
    "        \"family_x\": \"family\",\n",
    "        \"genus_x\": \"genus\",\n",
    "        \"unique_id_x\": \"unique_id\",\n",
    "        \"rights_x\": \"rights\",\n",
    "    },\n",
    "    inplace=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "left = left[\n",
    "    [\n",
    "        \"kingdom\",\n",
    "        \"phylum\",\n",
    "        \"class\",\n",
    "        \"order\",\n",
    "        \"family\",\n",
    "        \"genus\",\n",
    "        \"scientific_name\",\n",
    "        \"unique_id\",\n",
    "        \"rights\",\n",
    "    ]\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "left\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "right = outer.loc[\n",
    "    outer._merge == \"right_only\",\n",
    "    [\n",
    "        \"kingdom_y\",\n",
    "        \"phylum_y\",\n",
    "        \"class_y\",\n",
    "        \"order_y\",\n",
    "        \"family_y\",\n",
    "        \"genus_y\",\n",
    "        \"scientific_name\",\n",
    "        \"unique_id_y\",\n",
    "        \"rights_y\",\n",
    "    ],\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "right.rename(\n",
    "    columns={\n",
    "        \"kingdom_y\": \"kingdom\",\n",
    "        \"phylum_y\": \"phylum\",\n",
    "        \"class_y\": \"class\",\n",
    "        \"order_y\": \"order\",\n",
    "        \"family_y\": \"family\",\n",
    "        \"genus_y\": \"genus\",\n",
    "        \"unique_id_y\": \"unique_id\",\n",
    "        \"rights_y\": \"rights\",\n",
    "    },\n",
    "    inplace=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "right = right[\n",
    "    [\n",
    "        \"kingdom\",\n",
    "        \"phylum\",\n",
    "        \"class\",\n",
    "        \"order\",\n",
    "        \"family\",\n",
    "        \"genus\",\n",
    "        \"scientific_name\",\n",
    "        \"unique_id\",\n",
    "        \"rights\",\n",
    "    ]\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "right\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frames = [inner, left, right]\n",
    "\n",
    "# concatenate dataframes\n",
    "final = pd.concat(frames)\n",
    "\n",
    "# reset index\n",
    "final.reset_index(drop=True, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find unique values in scientific_name column of final\n",
    "species_unique = final[\"scientific_name\"].unique()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del frames, left, right, inner, outer, obis, samples, species_unique\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read cleaned df into a parquet file where user can input the file path\n",
    "df_merge_path = input(\"Enter the file path: \")\n",
    "\n",
    "\n",
    "# write df to parquet file using pandas to_parquet\n",
    "final.to_parquet(df_merge_path)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "eco",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
