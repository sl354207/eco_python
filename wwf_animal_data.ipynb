{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "# WWF ANIMAL DATA\n",
    "\n",
    "# read in all sheets of ods excel file for animal data\n",
    "df = pd.read_excel('/home/muskrat/Documents/eco_data_copy/main_eco_data/animal_copy.ods',\n",
    "                   index_col=0, sheet_name=None, engine=('odf'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# %%\n",
    "# WWF ANIMAL DATA\n",
    "\n",
    "# turn each sheet into dataframe\n",
    "ecoregions = df['ecoregions']\n",
    "ecoregions.reset_index(inplace=True)\n",
    "classes = df['class']\n",
    "common_names = df['common_names']\n",
    "common_names_bup = df['common_names_bup']\n",
    "eco_species = df['ecoregion_species']\n",
    "family = df['family']\n",
    "genus = df['genus']\n",
    "order = df['order_']\n",
    "species = df['species']\n",
    "# add unique id to each ecoregion and convert from int to str\n",
    "ranger = [*range(1, 1 + len(ecoregions))]\n",
    "rover = [str(x) for x in ranger]\n",
    "\n",
    "ecoregions.insert(0, 'unique_id', rover)\n",
    "\n",
    "# print(species.head())\n",
    "# print(genus.head())\n",
    "\n",
    "# df1 = common_names_bup.merge(common_names, how = 'outer' ,indicator=True).loc[lambda x : x['_merge']=='left_only']\n",
    "# df1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# %%\n",
    "# WWF ANIMAL DATA\n",
    "\n",
    "# join species and common name dataframes on species id\n",
    "species_common = pd.merge(species, common_names_bup, on='SPECIES_ID', how='left').reindex(\n",
    "    columns=['SPECIES_ID', 'SPECIES', 'COMMON_NAME', 'GENUS_ID'])\n",
    "# find missing value index\n",
    "print(species_common.loc[pd.isna(species_common[\"SPECIES\"]), :].index)\n",
    "\n",
    "# print(species_common.head(10))\n",
    "\n",
    "genus_species = pd.merge(species_common, genus, on='GENUS_ID', how='left').reindex(\n",
    "    columns=['SPECIES_ID', 'GENUS_ID', 'FAMILY_ID', 'GENUS', 'SPECIES', 'COMMON_NAME'])\n",
    "print(genus_species.loc[pd.isna(genus_species[\"GENUS\"]), :].index)\n",
    "\n",
    "family_genus = pd.merge(genus_species, family, on='FAMILY_ID', how='left').reindex(columns=[\n",
    "    'SPECIES_ID', 'GENUS_ID', 'FAMILY_ID', 'ORDER_ID', 'FAMILY', 'GENUS', 'SPECIES', 'COMMON_NAME'])\n",
    "print(family_genus.loc[pd.isna(family_genus[\"FAMILY\"]), :].index)\n",
    "\n",
    "order_family = pd.merge(family_genus, order, on='ORDER_ID', how='left').reindex(columns=[\n",
    "    'SPECIES_ID', 'GENUS_ID', 'FAMILY_ID', 'ORDER_ID', 'CLASS_ID', 'ORDER_DESC', 'FAMILY', 'GENUS', 'SPECIES', 'COMMON_NAME'])\n",
    "print(order_family.loc[pd.isna(order_family[\"ORDER_DESC\"]), :].index)\n",
    "\n",
    "class_order = pd.merge(order_family, classes, on='CLASS_ID', how='left').reindex(columns=[\n",
    "    'SPECIES_ID', 'GENUS_ID', 'FAMILY_ID', 'ORDER_ID', 'CLASS_ID', 'CLASS', 'ORDER_DESC', 'FAMILY', 'GENUS', 'SPECIES', 'COMMON_NAME'])\n",
    "print(class_order.loc[pd.isna(class_order[\"CLASS\"]), :].index)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# %%\n",
    "# WWF ANIMAL DATA\n",
    "\n",
    "# add genus and species columns into one scientific name column\n",
    "class_order['Scientific_Name'] = class_order['GENUS'].str.cat(\n",
    "    class_order['SPECIES'], sep=\" \")\n",
    "# print(class_order.loc[pd.isna(class_order[\"Scientific_Name\"]), :].index)\n",
    "\n",
    "# find all missing values\n",
    "# missing = class_order[class_order.isna().any(axis=1)]\n",
    "\n",
    "# fill missing values with unknown\n",
    "# class_order.fillna('Unknown', inplace=True)\n",
    "\n",
    "eco_mod = pd.merge(class_order, eco_species, on='SPECIES_ID', how='left').reindex(columns=[\n",
    "    'SPECIES_ID', 'GENUS_ID', 'FAMILY_ID', 'ORDER_ID', 'CLASS_ID', 'CLASS', 'ORDER_DESC', 'FAMILY', 'GENUS', 'SPECIES', 'Scientific_Name', 'COMMON_NAME', 'ECOREGION_CODE'])\n",
    "\n",
    "eco_mod_miss = eco_mod.loc[pd.isna(eco_mod[\"ECOREGION_CODE\"]), :].index\n",
    "\n",
    "\n",
    "ecos = pd.merge(eco_mod, ecoregions, on='ECOREGION_CODE', how='left').reindex(columns=[\n",
    "    'SPECIES_ID', 'GENUS_ID', 'FAMILY_ID', 'ORDER_ID', 'CLASS_ID', 'CLASS', 'ORDER_DESC', 'FAMILY', 'GENUS', 'SPECIES', 'Scientific_Name', 'COMMON_NAME', 'ECOREGION_CODE', 'ECOREGION_NAME', 'unique_id'])\n",
    "\n",
    "ecos.dropna(subset=['unique_id'], inplace=True)\n",
    "# %%\n",
    "# print(ecos.loc[pd.isna(ecos[\"ECOREGION_NAME\"]), :].index)\n",
    "\n",
    "# ecos.fillna('Unknown', inplace=True)\n",
    "\n",
    "# create a list of all ecoregion names that apply to same species id\n",
    "ecos1 = ecos.groupby('SPECIES_ID')['ECOREGION_NAME'].apply(list).reset_index()\n",
    "\n",
    "\n",
    "ecos2 = ecos.groupby('SPECIES_ID')['ECOREGION_CODE'].apply(list).reset_index()\n",
    "# print(ecos1.head(15))\n",
    "\n",
    "ecos3 = ecos.groupby('SPECIES_ID')['unique_id'].apply(list).reset_index()\n",
    "\n",
    "ecos4 = pd.merge(class_order, ecos1, on='SPECIES_ID', how='left').reindex(columns=[\n",
    "    'SPECIES_ID', 'GENUS_ID', 'FAMILY_ID', 'ORDER_ID', 'CLASS_ID', 'CLASS', 'ORDER_DESC', 'FAMILY', 'GENUS', 'SPECIES', 'Scientific_Name', 'COMMON_NAME', 'ECOREGION_NAME'])\n",
    "\n",
    "ecos5 = pd.merge(ecos4, ecos2, on='SPECIES_ID', how='left').reindex(columns=[\n",
    "    'SPECIES_ID', 'GENUS_ID', 'FAMILY_ID', 'ORDER_ID', 'CLASS_ID', 'CLASS', 'ORDER_DESC', 'FAMILY', 'GENUS', 'SPECIES', 'Scientific_Name', 'COMMON_NAME', 'ECOREGION_CODE', 'ECOREGION_NAME'])\n",
    "\n",
    "ecos6 = pd.merge(ecos5, ecos3, on='SPECIES_ID', how='left').reindex(columns=[\n",
    "    'SPECIES_ID', 'GENUS_ID', 'FAMILY_ID', 'ORDER_ID', 'CLASS_ID', 'CLASS', 'ORDER_DESC', 'FAMILY', 'GENUS', 'SPECIES', 'Scientific_Name', 'COMMON_NAME', 'ECOREGION_CODE', 'unique_id', 'ECOREGION_NAME'])\n",
    "\n",
    "final = ecos6[['SPECIES_ID', 'ORDER_DESC', 'FAMILY', 'CLASS', 'Scientific_Name',\n",
    "               'COMMON_NAME', 'ECOREGION_CODE', 'unique_id', 'ECOREGION_NAME']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# %%\n",
    "\n",
    "# create dataframe of all values in class column that are mammals\n",
    "mammals = final.loc[final['CLASS'].isin(['Mammalia'])].reset_index(drop=True)\n",
    "\n",
    "amphibians = final.loc[final['CLASS'].isin(\n",
    "    ['Amphibia'])].reset_index(drop=True)\n",
    "\n",
    "reptiles = final.loc[final['CLASS'].isin(['Reptilia'])].reset_index(drop=True)\n",
    "\n",
    "birds = final.loc[final['CLASS'].isin(['Aves'])].reset_index(drop=True)\n",
    "\n",
    "# create dataframe of all missing values\n",
    "unknown = final.loc[final['CLASS'].isna()]\n",
    "\n",
    "# create dataframe of all missing common names\n",
    "common_miss = final.loc[final['COMMON_NAME'].isna()]\n",
    "\n",
    "final.drop(final.index[[27729, 27779, 27971]], inplace=True,)\n",
    "final.reset_index(drop=True, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# %%\n",
    "\n",
    "# convert to json\n",
    "mammalj = mammals.to_json(orient='records', force_ascii=False)\n",
    "repr(mammalj)\n",
    "\n",
    "amphibianj = amphibians.to_json(orient='records', force_ascii=False)\n",
    "repr(amphibianj)\n",
    "\n",
    "reptilej = reptiles.to_json(orient='records', force_ascii=False)\n",
    "repr(reptilej)\n",
    "\n",
    "birdj = birds.to_json(orient='records', force_ascii=False)\n",
    "repr(birdj)\n",
    "\n",
    "finalj = final.to_json(orient='records', force_ascii=False)\n",
    "repr(finalj)\n",
    "\n",
    "final_miss = common_miss.to_json(orient='records', force_ascii=False)\n",
    "repr(final_miss)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# %%\n",
    "# WWF ANIMAL DATA\n",
    "\n",
    "# write to files\n",
    "# file = open(\"wwf_mammal.json\", \"w\")\n",
    "# file.write(mammalj)\n",
    "# file.close\n",
    "\n",
    "# file = open(\"wwf_amphibian.json\", \"w\")\n",
    "# file.write(amphibianj)\n",
    "# file.close\n",
    "\n",
    "# file = open(\"wwf_reptile.json\", \"w\")\n",
    "# file.write(reptilej)\n",
    "# file.close\n",
    "\n",
    "# file = open(\"birds_string.json\", \"w\")\n",
    "# file.write(birdj)\n",
    "# file.close\n",
    "\n",
    "file = open(\"wwf_animal_full.json\", \"w\")\n",
    "file.write(finalj)\n",
    "file.close\n",
    "\n",
    "file = open(\"wwf_animal_full_miss.json\", \"w\")\n",
    "file.write(final_miss)\n",
    "file.close\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
